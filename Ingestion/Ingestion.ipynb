{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c133c49284bc479a9d153d217b516b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed1988a03f864d80a160e3012593d170",
              "IPY_MODEL_b8ac729f5f4f4c8180299645255b0be8",
              "IPY_MODEL_9634814e1789454a89428f9d81cea7af"
            ],
            "layout": "IPY_MODEL_51222ead36474d76a11ee26618f15caa"
          }
        },
        "ed1988a03f864d80a160e3012593d170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15f000dfd9b840498694bd9e36f5c1fb",
            "placeholder": "​",
            "style": "IPY_MODEL_4ac40d0c8df546f9927070874a326b94",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "b8ac729f5f4f4c8180299645255b0be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37b632b4721b41c1a157b5af2be837e5",
            "max": 423,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_894cb3aa68164260b9cd7ec4335b20ef",
            "value": 423
          }
        },
        "9634814e1789454a89428f9d81cea7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffbfde7b971a4ac2bfd6c60675274d2c",
            "placeholder": "​",
            "style": "IPY_MODEL_c65510f19e5147dcbdea574144020764",
            "value": " 423/423 [00:00&lt;00:00, 27.4kB/s]"
          }
        },
        "51222ead36474d76a11ee26618f15caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15f000dfd9b840498694bd9e36f5c1fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac40d0c8df546f9927070874a326b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37b632b4721b41c1a157b5af2be837e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "894cb3aa68164260b9cd7ec4335b20ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffbfde7b971a4ac2bfd6c60675274d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c65510f19e5147dcbdea574144020764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "446fd1e4ffd146d4ae78d55268929123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0cc14c4afe34d02bafdd9c81e48fa80",
              "IPY_MODEL_12498405c33649899345e51883f4df9e",
              "IPY_MODEL_0ae6c859fcec4fdfa71d7284102f8be6"
            ],
            "layout": "IPY_MODEL_b777e17d806a4bbebab794b0718befb6"
          }
        },
        "c0cc14c4afe34d02bafdd9c81e48fa80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d25c0bc1b42146d585bfe296bcb74cd2",
            "placeholder": "​",
            "style": "IPY_MODEL_e88ebb3ea6ab4f5ab63de5ce099c964a",
            "value": "tokenizer_config.json: "
          }
        },
        "12498405c33649899345e51883f4df9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c5f56767964bf19e78c6d21b737303",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8cee1a59c8046bf85364acacad311f2",
            "value": 1
          }
        },
        "0ae6c859fcec4fdfa71d7284102f8be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b1323f3dd7645a694da595336541250",
            "placeholder": "​",
            "style": "IPY_MODEL_011b036f2b5a4693bde56dbddc0fcf94",
            "value": " 243k/? [00:00&lt;00:00, 13.1MB/s]"
          }
        },
        "b777e17d806a4bbebab794b0718befb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d25c0bc1b42146d585bfe296bcb74cd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e88ebb3ea6ab4f5ab63de5ce099c964a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3c5f56767964bf19e78c6d21b737303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a8cee1a59c8046bf85364acacad311f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b1323f3dd7645a694da595336541250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "011b036f2b5a4693bde56dbddc0fcf94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e867160be7a42deac648c62d32b0c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d540ae02b1ca40719e2940cd14ec10f3",
              "IPY_MODEL_9bcfb867c373425b92fcb3bb77763e79",
              "IPY_MODEL_55ecb40259b640cf861caff400378d45"
            ],
            "layout": "IPY_MODEL_efbf0a882e32484bb0efdfc7e718326d"
          }
        },
        "d540ae02b1ca40719e2940cd14ec10f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2398f0f3c47464b87e06babbfa87ac8",
            "placeholder": "​",
            "style": "IPY_MODEL_9c946c123f434aad97a56475b787c2e7",
            "value": "tokenizer.json: 100%"
          }
        },
        "9bcfb867c373425b92fcb3bb77763e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b35e2be52d0c4711b59353de51fc63f0",
            "max": 34600975,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8d3d269165844fb86a0f139a78621ff",
            "value": 34600975
          }
        },
        "55ecb40259b640cf861caff400378d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98f53075edc545c09308ba43f6ab129b",
            "placeholder": "​",
            "style": "IPY_MODEL_3a0d99fc989a4814b8e427ffa4b96b26",
            "value": " 34.6M/34.6M [00:00&lt;00:00, 42.9MB/s]"
          }
        },
        "efbf0a882e32484bb0efdfc7e718326d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2398f0f3c47464b87e06babbfa87ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c946c123f434aad97a56475b787c2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b35e2be52d0c4711b59353de51fc63f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8d3d269165844fb86a0f139a78621ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98f53075edc545c09308ba43f6ab129b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a0d99fc989a4814b8e427ffa4b96b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d83dcf768cdd4fccb31e9260bcab7607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c39c771e7c804626b26c13a2923c78ba",
              "IPY_MODEL_81b8673718c24f3aafbabd1ef3b5b5de",
              "IPY_MODEL_695a50084a344f9daf2bd160909cf959"
            ],
            "layout": "IPY_MODEL_f7fe9b276c0a43159c277300cc4a278c"
          }
        },
        "c39c771e7c804626b26c13a2923c78ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b6976ab58254153bf43ee6b919910ef",
            "placeholder": "​",
            "style": "IPY_MODEL_40b66427cfd64f37a7addf42800ae83a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "81b8673718c24f3aafbabd1ef3b5b5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dccd191c58e46b48e5bf9e89df91255",
            "max": 733,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1bf5c455e054abcbe20fc060278cf6c",
            "value": 733
          }
        },
        "695a50084a344f9daf2bd160909cf959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72ef6480e0d543aa9b2c28d36be55ac0",
            "placeholder": "​",
            "style": "IPY_MODEL_e1c15be38bc048d38f367c398ab06d54",
            "value": " 733/733 [00:00&lt;00:00, 72.1kB/s]"
          }
        },
        "f7fe9b276c0a43159c277300cc4a278c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b6976ab58254153bf43ee6b919910ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b66427cfd64f37a7addf42800ae83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dccd191c58e46b48e5bf9e89df91255": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1bf5c455e054abcbe20fc060278cf6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72ef6480e0d543aa9b2c28d36be55ac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c15be38bc048d38f367c398ab06d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d24d1ea4ebb4197b496d07a19fe179b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65b267ffc0594f2ca23d68c148a95ff2",
              "IPY_MODEL_0f84516705824e8d90049a6411b192a9",
              "IPY_MODEL_b39c75b4659f4f6ba27a81453a22bcac"
            ],
            "layout": "IPY_MODEL_a38d3bd4db624ec094f035fec2dccdfc"
          }
        },
        "65b267ffc0594f2ca23d68c148a95ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc6afea5bc6f429992a05484ecb0b5bd",
            "placeholder": "​",
            "style": "IPY_MODEL_a24d877222bb449c948e6e0e76643907",
            "value": "config.json: "
          }
        },
        "0f84516705824e8d90049a6411b192a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2231752f4f9041d5aab8b0a2bcbab0e8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_757620fc4dda44dcb0df319accca3a25",
            "value": 1
          }
        },
        "b39c75b4659f4f6ba27a81453a22bcac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6358b74549e64e5697671f6671e6435d",
            "placeholder": "​",
            "style": "IPY_MODEL_08a4c1635dee4135a7665214c4ba12af",
            "value": " 1.36k/? [00:00&lt;00:00, 151kB/s]"
          }
        },
        "a38d3bd4db624ec094f035fec2dccdfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc6afea5bc6f429992a05484ecb0b5bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24d877222bb449c948e6e0e76643907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2231752f4f9041d5aab8b0a2bcbab0e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "757620fc4dda44dcb0df319accca3a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6358b74549e64e5697671f6671e6435d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08a4c1635dee4135a7665214c4ba12af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "720dc9869d84440babbf172c543f9ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f157cc8d2f046188f4d9b77f72861b4",
              "IPY_MODEL_296b11b7ea2249828a609f0059b967aa",
              "IPY_MODEL_c1ed84418b6d4864a41e5b72c4312036"
            ],
            "layout": "IPY_MODEL_0de7beb4a46d4af69ebe0277efd801c9"
          }
        },
        "5f157cc8d2f046188f4d9b77f72861b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea2d029235cc4269bc2f455bbfd859c0",
            "placeholder": "​",
            "style": "IPY_MODEL_52ba8aab7e934d0bbb03ea55ba426669",
            "value": "model.safetensors.index.json: "
          }
        },
        "296b11b7ea2249828a609f0059b967aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af7d0011bc5349f6af205e520edfa25b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b6b096ba3f241128ae96aa2849a29cc",
            "value": 1
          }
        },
        "c1ed84418b6d4864a41e5b72c4312036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2babb6d0f42a44648ee406cb406e9afe",
            "placeholder": "​",
            "style": "IPY_MODEL_a8ac3665a38e4ba9a2bac2f9614536cb",
            "value": " 65.1k/? [00:00&lt;00:00, 6.42MB/s]"
          }
        },
        "0de7beb4a46d4af69ebe0277efd801c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea2d029235cc4269bc2f455bbfd859c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ba8aab7e934d0bbb03ea55ba426669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af7d0011bc5349f6af205e520edfa25b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4b6b096ba3f241128ae96aa2849a29cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2babb6d0f42a44648ee406cb406e9afe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ac3665a38e4ba9a2bac2f9614536cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f69665eda2aa4930b2cec473adc51dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed4dd5e2a0be4a0c82774ed35776a8be",
              "IPY_MODEL_42d1360dfe174bef981714680ecb9e80",
              "IPY_MODEL_50bb528c63ba4a2a91a6efc0d0d36ef4"
            ],
            "layout": "IPY_MODEL_2e73961387dd41b3b1efd3fcc7a69a89"
          }
        },
        "ed4dd5e2a0be4a0c82774ed35776a8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_412a33854dee4bef8042f256a98c26bd",
            "placeholder": "​",
            "style": "IPY_MODEL_e9fcd6c8c9704945a6a5ac0faeb7b952",
            "value": "Fetching 2 files: 100%"
          }
        },
        "42d1360dfe174bef981714680ecb9e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e6ba704bcfc4771875e6d7d42fbdea0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5506ae792e645279c9a7f68b9ed2dd7",
            "value": 2
          }
        },
        "50bb528c63ba4a2a91a6efc0d0d36ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_772e90a880c94822bf34cc766e4826a9",
            "placeholder": "​",
            "style": "IPY_MODEL_66501632cc7746c985b65e1410c7675b",
            "value": " 2/2 [03:50&lt;00:00, 230.76s/it]"
          }
        },
        "2e73961387dd41b3b1efd3fcc7a69a89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "412a33854dee4bef8042f256a98c26bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9fcd6c8c9704945a6a5ac0faeb7b952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e6ba704bcfc4771875e6d7d42fbdea0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5506ae792e645279c9a7f68b9ed2dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "772e90a880c94822bf34cc766e4826a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66501632cc7746c985b65e1410c7675b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b90f6322f6474c498038080ee619984b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e971d0bd755646dd82f6cc13214f41e2",
              "IPY_MODEL_4145260975794139b66c381904bc3c0e",
              "IPY_MODEL_ad12f87ee799430ba83a44b31c16db57"
            ],
            "layout": "IPY_MODEL_86b6113758bc473bbb9401340a10c786"
          }
        },
        "e971d0bd755646dd82f6cc13214f41e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81526448b76d426b8fb4e3a92be08562",
            "placeholder": "​",
            "style": "IPY_MODEL_074af77f217f44229b02cceb803a8a23",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "4145260975794139b66c381904bc3c0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb76c0f28bcc41aab204236fefd340b0",
            "max": 4986816144,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7402d87d40344f8f975ea966af5b4621",
            "value": 4986816144
          }
        },
        "ad12f87ee799430ba83a44b31c16db57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a1480840ef84936acac6740aa4517ec",
            "placeholder": "​",
            "style": "IPY_MODEL_c98413797b5344ff9eefa68fde68fd3f",
            "value": " 4.99G/4.99G [03:50&lt;00:00, 47.5MB/s]"
          }
        },
        "86b6113758bc473bbb9401340a10c786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81526448b76d426b8fb4e3a92be08562": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "074af77f217f44229b02cceb803a8a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb76c0f28bcc41aab204236fefd340b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7402d87d40344f8f975ea966af5b4621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a1480840ef84936acac6740aa4517ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c98413797b5344ff9eefa68fde68fd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6588bbb109b4019a88c72168aa23acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_714488bdeb084f6c8b8bf3cd40365983",
              "IPY_MODEL_c17f52a992fa45ffa1437dde375d7132",
              "IPY_MODEL_443768290602489e971ecb95be0c26ce"
            ],
            "layout": "IPY_MODEL_30309a73ae8549f198d7c7d321b409fa"
          }
        },
        "714488bdeb084f6c8b8bf3cd40365983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12769906e28a4be8ab6f5bbd18009a7d",
            "placeholder": "​",
            "style": "IPY_MODEL_d8d4c07dda90462a89b6faf85b0a7ded",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "c17f52a992fa45ffa1437dde375d7132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_128b60e6ea9a4dd4932d891bdba13c52",
            "max": 862495464,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d829c86f125b47b8bb2161c46ead3f1b",
            "value": 862495464
          }
        },
        "443768290602489e971ecb95be0c26ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58e0ff4ee9cd4d2299b7bd18186d4b18",
            "placeholder": "​",
            "style": "IPY_MODEL_dbbf434046cf4ac58a74a190fbbea094",
            "value": " 862M/862M [02:36&lt;00:00, 5.88MB/s]"
          }
        },
        "30309a73ae8549f198d7c7d321b409fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12769906e28a4be8ab6f5bbd18009a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8d4c07dda90462a89b6faf85b0a7ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "128b60e6ea9a4dd4932d891bdba13c52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d829c86f125b47b8bb2161c46ead3f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58e0ff4ee9cd4d2299b7bd18186d4b18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbf434046cf4ac58a74a190fbbea094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efba68d3ebe242d4b9c35bf1c2cd3196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4ca68e870c842dabe06b02283649b72",
              "IPY_MODEL_d99ee3980fd04c33aefb3a4dc8df6d27",
              "IPY_MODEL_f87baa6a52864d75a48944421d22406b"
            ],
            "layout": "IPY_MODEL_864f350dc2ff4a69aee446c6aff38d53"
          }
        },
        "d4ca68e870c842dabe06b02283649b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d68d615516c54db2b2807b8bf84eee27",
            "placeholder": "​",
            "style": "IPY_MODEL_5cbd93e6e2c0485390993982bc65fd55",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d99ee3980fd04c33aefb3a4dc8df6d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fa007cd6ae74e76a92d465a0b3425bf",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07b66d2dbc3d4b75825962a495127ef9",
            "value": 2
          }
        },
        "f87baa6a52864d75a48944421d22406b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_760f48f9d84f475d96c0a8c307927d23",
            "placeholder": "​",
            "style": "IPY_MODEL_5cd0077caca7406e85b48ae96638fdf3",
            "value": " 2/2 [00:00&lt;00:00, 19.66it/s]"
          }
        },
        "864f350dc2ff4a69aee446c6aff38d53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d68d615516c54db2b2807b8bf84eee27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cbd93e6e2c0485390993982bc65fd55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fa007cd6ae74e76a92d465a0b3425bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07b66d2dbc3d4b75825962a495127ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "760f48f9d84f475d96c0a8c307927d23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd0077caca7406e85b48ae96638fdf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title 1) System setup: system libs + pinned Python deps (safe for spaCy/NumPy)\n",
        "!apt-get update -y -qq\n",
        "!apt-get install -y -qq poppler-utils tesseract-ocr\n",
        "\n",
        "# Clean conflicting NLP stack to avoid ABI issues\n",
        "!pip uninstall -y -q spacy thinc scispacy numpy catalogue cymem murmurhash preshed srsly wasabi blis || true\n",
        "\n",
        "# Install core Python packages (pin NumPy and NLP stack)\n",
        "!pip install -q --no-cache-dir \"numpy==2.0.2\" \"spacy==3.7.5\" \"thinc==8.2.5\" \"scispacy==0.5.4\"\n",
        "\n",
        "# SciSpacy model\n",
        "!pip install -q \"https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_ner_bionlp13cg_md-0.5.4.tar.gz\"\n",
        "\n",
        "# Core utilities\n",
        "!pip install -q --no-deps pillow pdf2image pytesseract\n",
        "\n",
        "# Vector + Graph\n",
        "!pip install -q pymilvus==2.5.3 neo4j python-dotenv\n",
        "\n",
        "# Models - FIXED: Install colpali-engine correctly\n",
        "!pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q \"transformers>=4.45.0\" \"accelerate\" \"safetensors\" \"einops\"\n",
        "!pip install -q git+https://github.com/illuin-tech/colpali.git\n",
        "\n",
        "# Optional: clear any residual state\n",
        "import os, gc, torch\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"✓ System + Python deps installed\")\n",
        "print(\"\\n⚠️ IMPORTANT: RESTART RUNTIME NOW!\")\n",
        "print(\"   Runtime → Restart Runtime\")\n",
        "print(\"   Then run from Cell 2 onwards\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PICTL7Sv8YO",
        "outputId": "e967671b-7160-44f9-b936-50207156f700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.10_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.10) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.10) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[33mWARNING: Skipping scispacy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Cannot install numpy==2.0.2, spacy==3.7.5 and thinc==8.2.5 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.3/869.3 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.0/865.0 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for en_ner_bionlp13cg_md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.8/325.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires grpcio>=1.71.2, but you have grpcio 1.67.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.3/472.3 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m141.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for colpali_engine (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m✓ System + Python deps installed\n",
            "\n",
            "⚠️ IMPORTANT: RESTART RUNTIME NOW!\n",
            "   Runtime → Restart Runtime\n",
            "   Then run from Cell 2 onwards\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2) Imports and environment check\n",
        "import os\n",
        "import json\n",
        "import gc\n",
        "import getpass\n",
        "import shutil\n",
        "import traceback\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "import spacy\n",
        "\n",
        "from neo4j import GraphDatabase\n",
        "from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility\n",
        "\n",
        "# Transformers and vision models\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "# Larger images may trigger PIL safety checks; disable\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__} | CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Load SciSpacy NER model\n",
        "print(\"→ Loading SciSpacy NER...\")\n",
        "nlp = spacy.load(\"en_ner_bionlp13cg_md\")\n",
        "print(\"✓ SciSpacy loaded\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-05T09:02:58.803724Z",
          "iopub.execute_input": "2025-10-05T09:02:58.804218Z",
          "iopub.status.idle": "2025-10-05T09:03:06.544486Z",
          "shell.execute_reply.started": "2025-10-05T09:02:58.804189Z",
          "shell.execute_reply": "2025-10-05T09:03:06.54353Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBDt-Le8v8YP",
        "outputId": "61231633-5e9c-4437-fecd-03171715bda7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch: 2.7.1+cu126 | CUDA available: True\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 15.83 GB\n",
            "Device: cuda\n",
            "→ Loading SciSpacy NER...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
            "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ SciSpacy loaded\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3) Configuration (edit paths and options as needed)\n",
        "\n",
        "# If using Colab, you'll probably place PDFs under /content/pdfs\n",
        "DATASET_PATH = \"/content/pdfs\"  #@param {type:\"string\"}\n",
        "WORKING_DIR = \"/content/working\"  #@param {type:\"string\"}\n",
        "\n",
        "# In test mode, only process the first few PDFs and reduce load\n",
        "TEST_MODE = True  #@param {type:\"boolean\"}\n",
        "LIMIT = 30 if TEST_MODE else None\n",
        "BATCH_SIZE = 1  #@param {type:\"integer\"}\n",
        "DPI = 200  #@param {type:\"integer\"}\n",
        "\n",
        "# Neo4j config - provide your Aura or self-hosted credentials\n",
        "print(\"\\n=== Neo4j Configuration ===\")\n",
        "NEO4J_URI = input(\"Enter NEO4J_URI (e.g., neo4j+s://xxxxx.databases.neo4j.io): \").strip()\n",
        "NEO4J_USER = input(\"Enter NEO4J_USER (e.g., neo4j): \").strip()\n",
        "NEO4J_PASSWORD = getpass.getpass(\"Enter NEO4J_PASSWORD: \").strip()\n",
        "\n",
        "# Zilliz (Milvus Cloud) config\n",
        "print(\"\\n=== Zilliz Configuration ===\")\n",
        "ZILLIZ_URI = input(\"Enter Zilliz URI (https://xxx.cloud.zilliz.com): \").strip()\n",
        "ZILLIZ_TOKEN = getpass.getpass(\"Enter Zilliz API token: \").strip()\n",
        "\n",
        "# Make sure working dirs exist\n",
        "Path(WORKING_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(DATASET_PATH).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\n✓ Configuration loaded\")\n",
        "print(f\"  Test Mode: {TEST_MODE}\")\n",
        "print(f\"  Dataset Path: {DATASET_PATH}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-04T15:02:16.257Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fskw0RQv8YP",
        "outputId": "518edc12-6bcc-4812-9303-4b8436105c06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Neo4j Configuration ===\n",
            "Enter NEO4J_URI (e.g., neo4j+s://xxxxx.databases.neo4j.io): neo4j+s://239d94db.databases.neo4j.io\n",
            "Enter NEO4J_USER (e.g., neo4j): neo4j\n",
            "Enter NEO4J_PASSWORD: ··········\n",
            "\n",
            "=== Zilliz Configuration ===\n",
            "Enter Zilliz URI (https://xxx.cloud.zilliz.com): https://in03-0a05f9ae02837d6.serverless.aws-eu-central-1.cloud.zilliz.com\n",
            "Enter Zilliz API token: ··········\n",
            "\n",
            "✓ Configuration loaded\n",
            "  Test Mode: True\n",
            "  Dataset Path: /content/pdfs\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4) Initialize connections (Neo4j + Zilliz)\n",
        "print(\"\\n=== INITIALIZING CONNECTIONS ===\\n\")\n",
        "\n",
        "# Neo4j\n",
        "try:\n",
        "    neo4j_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
        "    with neo4j_driver.session() as session:\n",
        "        session.run(\"RETURN 1\")\n",
        "    print(\"✓ Neo4j connected\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Neo4j connection failed: {e}\")\n",
        "    raise\n",
        "\n",
        "# Zilliz (Milvus Cloud)\n",
        "try:\n",
        "    connections.connect(alias=\"default\", uri=ZILLIZ_URI, token=ZILLIZ_TOKEN)\n",
        "    print(\"✓ Zilliz connected\")\n",
        "    print(f\"  Server version: {utility.get_server_version()}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Zilliz connection failed: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-04T15:02:16.257Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MorjwNHcv8YQ",
        "outputId": "e6513181-6a28-4df3-e384-1ba4d18264dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== INITIALIZING CONNECTIONS ===\n",
            "\n",
            "✓ Neo4j connected\n",
            "✓ Zilliz connected\n",
            "  Server version: Zilliz Cloud Vector Database(Compatible with Milvus 2.5)\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5) Load vision embedding model (ColPali - FIXED with proper pooling)\n",
        "print(\"\\n=== LOADING VISION MODEL ===\\n\")\n",
        "USING_CLIP_FALLBACK = False\n",
        "\n",
        "colpali_model = None\n",
        "colpali_processor = None\n",
        "\n",
        "try:\n",
        "    # FIXED: Correct import paths for ColPali v1.3\n",
        "    print(\"→ Loading ColPali v1.3...\")\n",
        "\n",
        "    # Try import method 1: Direct imports\n",
        "    try:\n",
        "        from colpali_engine.models.paligemma.colpali.modeling_colpali import ColPali\n",
        "        from colpali_engine.models.paligemma.colpali.processing_colpali import ColPaliProcessor\n",
        "        print(\"  ✓ Using ColPali direct imports\")\n",
        "    except ImportError:\n",
        "        # Try import method 2: Package-level imports\n",
        "        try:\n",
        "            from colpali_engine.models import ColPali\n",
        "            from colpali_engine.models import ColPaliProcessor\n",
        "            print(\"  ✓ Using ColPali package imports\")\n",
        "        except ImportError:\n",
        "            # Try import method 3: Simpler path\n",
        "            from colpali_engine import ColPali, ColPaliProcessor\n",
        "            print(\"  ✓ Using ColPali simple imports\")\n",
        "\n",
        "    colpali_model_name = \"vidore/colpali-v1.3-hf\"\n",
        "\n",
        "    # Load processor\n",
        "    print(\"  → Loading processor...\")\n",
        "    try:\n",
        "        colpali_processor = ColPaliProcessor.from_pretrained(\n",
        "            colpali_model_name,\n",
        "            use_fast=True  # Suppress the warning\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"  ⚠ ColPaliProcessor failed: {e}, trying AutoProcessor\")\n",
        "        colpali_processor = AutoProcessor.from_pretrained(\n",
        "            colpali_model_name,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "    # Load model\n",
        "    print(\"  → Loading model...\")\n",
        "    colpali_model = ColPali.from_pretrained(\n",
        "        colpali_model_name,\n",
        "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "        device_map=\"auto\" if device == \"cuda\" else None,\n",
        "    ).eval()\n",
        "\n",
        "    print(f\"✓ ColPali v1.3 loaded successfully on {device.upper()}\")\n",
        "    USING_CLIP_FALLBACK = False\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"⚠ ColPali load failed: {e}\")\n",
        "    print(traceback.format_exc())\n",
        "    print(\"\\n→ Falling back to CLIP\")\n",
        "\n",
        "    try:\n",
        "        from transformers import CLIPProcessor, CLIPModel\n",
        "        clip_model_name = \"openai/clip-vit-base-patch32\"\n",
        "        colpali_processor = CLIPProcessor.from_pretrained(clip_model_name)\n",
        "        colpali_model = CLIPModel.from_pretrained(\n",
        "            clip_model_name,\n",
        "            torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
        "        ).eval()\n",
        "        if device == \"cuda\":\n",
        "            colpali_model = colpali_model.to(device)\n",
        "        USING_CLIP_FALLBACK = True\n",
        "        print(\"✓ CLIP model loaded as fallback\")\n",
        "    except Exception as e2:\n",
        "        print(f\"✗ CLIP fallback also failed: {e2}\")\n",
        "        raise\n",
        "\n",
        "# FIXED: Detect embedding dimension with proper pooling for ColPali\n",
        "# FIXED: Detect embedding dimension with proper pooling for ColPali\n",
        "def detect_embedding_dim():\n",
        "    print(\"\\n=== DETECTING EMBEDDING DIMENSION ===\")\n",
        "    test_img = Image.new('RGB', (224, 224), color='white')\n",
        "    try:\n",
        "        if USING_CLIP_FALLBACK:\n",
        "            inputs = colpali_processor(images=[test_img], return_tensors=\"pt\", padding=True)\n",
        "        else:\n",
        "            # ColPali expects <image> token in text\n",
        "            inputs = colpali_processor(\n",
        "                text=[\"<image>\"],\n",
        "                images=[test_img],\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True\n",
        "            )\n",
        "\n",
        "        if device == \"cuda\":\n",
        "            inputs = {k: (v.to(device) if hasattr(v, \"to\") else v) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if USING_CLIP_FALLBACK:\n",
        "                emb = colpali_model.get_image_features(**inputs)\n",
        "                emb = emb.reshape(emb.shape[0], -1)\n",
        "                dim = int(emb.shape[-1])\n",
        "                num_patches = 1\n",
        "            else:\n",
        "                # ColPali-specific embedding extraction\n",
        "                out = colpali_model(**inputs)\n",
        "\n",
        "                if hasattr(out, \"last_hidden_state\"):\n",
        "                    emb = out.last_hidden_state\n",
        "                elif hasattr(out, \"embeddings\"):\n",
        "                    emb = out.embeddings\n",
        "                elif isinstance(out, torch.Tensor):\n",
        "                    emb = out\n",
        "                else:\n",
        "                    emb = out[0] if isinstance(out, (tuple, list)) else out\n",
        "\n",
        "                print(f\"  Raw ColPali output shape: {emb.shape}\")\n",
        "\n",
        "                # CRITICAL: Keep multi-vector output [batch, num_patches, 128]\n",
        "                if len(emb.shape) == 3:\n",
        "                    num_patches = emb.shape[1]\n",
        "                    dim = emb.shape[2]\n",
        "                    print(f\"  → Multi-vector output: {num_patches} patches × {dim} dimensions\")\n",
        "                else:\n",
        "                    emb = emb.reshape(emb.shape[0], -1)\n",
        "                    dim = int(emb.shape[-1])\n",
        "                    num_patches = 1\n",
        "\n",
        "        print(f\"✓ Embedding dimension per patch: {dim}\")\n",
        "        print(f\"✓ Number of patches per image: {num_patches}\")\n",
        "        print(f\"  Model: {type(colpali_model).__name__}\")\n",
        "\n",
        "        # Cleanup\n",
        "        del inputs, out, emb, test_img\n",
        "        if device == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        return dim, num_patches\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Dimension detection failed: {e}\")\n",
        "        print(traceback.format_exc())\n",
        "        default_dim = 512 if USING_CLIP_FALLBACK else 128\n",
        "        default_patches = 1 if USING_CLIP_FALLBACK else 1024\n",
        "        print(f\"→ Using defaults: {default_dim} dim, {default_patches} patches\")\n",
        "        return default_dim, default_patches\n",
        "\n",
        "EMBEDDING_DIM, NUM_PATCHES = detect_embedding_dim()\n",
        "print(f\"\\n✓ Final config: {EMBEDDING_DIM}D × {NUM_PATCHES} patches\")\n",
        "print(f\"✓ Using CLIP fallback: {USING_CLIP_FALLBACK}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-04T15:02:16.258Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843,
          "referenced_widgets": [
            "c133c49284bc479a9d153d217b516b6d",
            "ed1988a03f864d80a160e3012593d170",
            "b8ac729f5f4f4c8180299645255b0be8",
            "9634814e1789454a89428f9d81cea7af",
            "51222ead36474d76a11ee26618f15caa",
            "15f000dfd9b840498694bd9e36f5c1fb",
            "4ac40d0c8df546f9927070874a326b94",
            "37b632b4721b41c1a157b5af2be837e5",
            "894cb3aa68164260b9cd7ec4335b20ef",
            "ffbfde7b971a4ac2bfd6c60675274d2c",
            "c65510f19e5147dcbdea574144020764",
            "446fd1e4ffd146d4ae78d55268929123",
            "c0cc14c4afe34d02bafdd9c81e48fa80",
            "12498405c33649899345e51883f4df9e",
            "0ae6c859fcec4fdfa71d7284102f8be6",
            "b777e17d806a4bbebab794b0718befb6",
            "d25c0bc1b42146d585bfe296bcb74cd2",
            "e88ebb3ea6ab4f5ab63de5ce099c964a",
            "e3c5f56767964bf19e78c6d21b737303",
            "a8cee1a59c8046bf85364acacad311f2",
            "0b1323f3dd7645a694da595336541250",
            "011b036f2b5a4693bde56dbddc0fcf94",
            "1e867160be7a42deac648c62d32b0c5a",
            "d540ae02b1ca40719e2940cd14ec10f3",
            "9bcfb867c373425b92fcb3bb77763e79",
            "55ecb40259b640cf861caff400378d45",
            "efbf0a882e32484bb0efdfc7e718326d",
            "c2398f0f3c47464b87e06babbfa87ac8",
            "9c946c123f434aad97a56475b787c2e7",
            "b35e2be52d0c4711b59353de51fc63f0",
            "b8d3d269165844fb86a0f139a78621ff",
            "98f53075edc545c09308ba43f6ab129b",
            "3a0d99fc989a4814b8e427ffa4b96b26",
            "d83dcf768cdd4fccb31e9260bcab7607",
            "c39c771e7c804626b26c13a2923c78ba",
            "81b8673718c24f3aafbabd1ef3b5b5de",
            "695a50084a344f9daf2bd160909cf959",
            "f7fe9b276c0a43159c277300cc4a278c",
            "9b6976ab58254153bf43ee6b919910ef",
            "40b66427cfd64f37a7addf42800ae83a",
            "0dccd191c58e46b48e5bf9e89df91255",
            "a1bf5c455e054abcbe20fc060278cf6c",
            "72ef6480e0d543aa9b2c28d36be55ac0",
            "e1c15be38bc048d38f367c398ab06d54",
            "6d24d1ea4ebb4197b496d07a19fe179b",
            "65b267ffc0594f2ca23d68c148a95ff2",
            "0f84516705824e8d90049a6411b192a9",
            "b39c75b4659f4f6ba27a81453a22bcac",
            "a38d3bd4db624ec094f035fec2dccdfc",
            "fc6afea5bc6f429992a05484ecb0b5bd",
            "a24d877222bb449c948e6e0e76643907",
            "2231752f4f9041d5aab8b0a2bcbab0e8",
            "757620fc4dda44dcb0df319accca3a25",
            "6358b74549e64e5697671f6671e6435d",
            "08a4c1635dee4135a7665214c4ba12af",
            "720dc9869d84440babbf172c543f9ef8",
            "5f157cc8d2f046188f4d9b77f72861b4",
            "296b11b7ea2249828a609f0059b967aa",
            "c1ed84418b6d4864a41e5b72c4312036",
            "0de7beb4a46d4af69ebe0277efd801c9",
            "ea2d029235cc4269bc2f455bbfd859c0",
            "52ba8aab7e934d0bbb03ea55ba426669",
            "af7d0011bc5349f6af205e520edfa25b",
            "4b6b096ba3f241128ae96aa2849a29cc",
            "2babb6d0f42a44648ee406cb406e9afe",
            "a8ac3665a38e4ba9a2bac2f9614536cb",
            "f69665eda2aa4930b2cec473adc51dc0",
            "ed4dd5e2a0be4a0c82774ed35776a8be",
            "42d1360dfe174bef981714680ecb9e80",
            "50bb528c63ba4a2a91a6efc0d0d36ef4",
            "2e73961387dd41b3b1efd3fcc7a69a89",
            "412a33854dee4bef8042f256a98c26bd",
            "e9fcd6c8c9704945a6a5ac0faeb7b952",
            "3e6ba704bcfc4771875e6d7d42fbdea0",
            "f5506ae792e645279c9a7f68b9ed2dd7",
            "772e90a880c94822bf34cc766e4826a9",
            "66501632cc7746c985b65e1410c7675b",
            "b90f6322f6474c498038080ee619984b",
            "e971d0bd755646dd82f6cc13214f41e2",
            "4145260975794139b66c381904bc3c0e",
            "ad12f87ee799430ba83a44b31c16db57",
            "86b6113758bc473bbb9401340a10c786",
            "81526448b76d426b8fb4e3a92be08562",
            "074af77f217f44229b02cceb803a8a23",
            "bb76c0f28bcc41aab204236fefd340b0",
            "7402d87d40344f8f975ea966af5b4621",
            "4a1480840ef84936acac6740aa4517ec",
            "c98413797b5344ff9eefa68fde68fd3f",
            "b6588bbb109b4019a88c72168aa23acf",
            "714488bdeb084f6c8b8bf3cd40365983",
            "c17f52a992fa45ffa1437dde375d7132",
            "443768290602489e971ecb95be0c26ce",
            "30309a73ae8549f198d7c7d321b409fa",
            "12769906e28a4be8ab6f5bbd18009a7d",
            "d8d4c07dda90462a89b6faf85b0a7ded",
            "128b60e6ea9a4dd4932d891bdba13c52",
            "d829c86f125b47b8bb2161c46ead3f1b",
            "58e0ff4ee9cd4d2299b7bd18186d4b18",
            "dbbf434046cf4ac58a74a190fbbea094",
            "efba68d3ebe242d4b9c35bf1c2cd3196",
            "d4ca68e870c842dabe06b02283649b72",
            "d99ee3980fd04c33aefb3a4dc8df6d27",
            "f87baa6a52864d75a48944421d22406b",
            "864f350dc2ff4a69aee446c6aff38d53",
            "d68d615516c54db2b2807b8bf84eee27",
            "5cbd93e6e2c0485390993982bc65fd55",
            "7fa007cd6ae74e76a92d465a0b3425bf",
            "07b66d2dbc3d4b75825962a495127ef9",
            "760f48f9d84f475d96c0a8c307927d23",
            "5cd0077caca7406e85b48ae96638fdf3"
          ]
        },
        "id": "rW2qxHyrv8YQ",
        "outputId": "0b320672-97ee-4446-bbde-43f5755a9bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== LOADING VISION MODEL ===\n",
            "\n",
            "→ Loading ColPali v1.3...\n",
            "  ✓ Using ColPali direct imports\n",
            "  → Loading processor...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/423 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c133c49284bc479a9d153d217b516b6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "446fd1e4ffd146d4ae78d55268929123"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/34.6M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e867160be7a42deac648c62d32b0c5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/733 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d83dcf768cdd4fccb31e9260bcab7607"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  → Loading model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d24d1ea4ebb4197b496d07a19fe179b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "720dc9869d84440babbf172c543f9ef8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f69665eda2aa4930b2cec473adc51dc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b90f6322f6474c498038080ee619984b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/862M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6588bbb109b4019a88c72168aa23acf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efba68d3ebe242d4b9c35bf1c2cd3196"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ColPali were not initialized from the model checkpoint at vidore/colpali-v1.3-hf and are newly initialized: ['custom_text_proj.bias', 'custom_text_proj.weight', 'model.model.language_model.embed_tokens.weight', 'model.model.language_model.layers.0.input_layernorm.weight', 'model.model.language_model.layers.0.mlp.down_proj.weight', 'model.model.language_model.layers.0.mlp.gate_proj.weight', 'model.model.language_model.layers.0.mlp.up_proj.weight', 'model.model.language_model.layers.0.post_attention_layernorm.weight', 'model.model.language_model.layers.0.self_attn.k_proj.weight', 'model.model.language_model.layers.0.self_attn.o_proj.weight', 'model.model.language_model.layers.0.self_attn.q_proj.weight', 'model.model.language_model.layers.0.self_attn.v_proj.weight', 'model.model.language_model.layers.1.input_layernorm.weight', 'model.model.language_model.layers.1.mlp.down_proj.weight', 'model.model.language_model.layers.1.mlp.gate_proj.weight', 'model.model.language_model.layers.1.mlp.up_proj.weight', 'model.model.language_model.layers.1.post_attention_layernorm.weight', 'model.model.language_model.layers.1.self_attn.k_proj.weight', 'model.model.language_model.layers.1.self_attn.o_proj.weight', 'model.model.language_model.layers.1.self_attn.q_proj.weight', 'model.model.language_model.layers.1.self_attn.v_proj.weight', 'model.model.language_model.layers.10.input_layernorm.weight', 'model.model.language_model.layers.10.mlp.down_proj.weight', 'model.model.language_model.layers.10.mlp.gate_proj.weight', 'model.model.language_model.layers.10.mlp.up_proj.weight', 'model.model.language_model.layers.10.post_attention_layernorm.weight', 'model.model.language_model.layers.10.self_attn.k_proj.weight', 'model.model.language_model.layers.10.self_attn.o_proj.weight', 'model.model.language_model.layers.10.self_attn.q_proj.weight', 'model.model.language_model.layers.10.self_attn.v_proj.weight', 'model.model.language_model.layers.11.input_layernorm.weight', 'model.model.language_model.layers.11.mlp.down_proj.weight', 'model.model.language_model.layers.11.mlp.gate_proj.weight', 'model.model.language_model.layers.11.mlp.up_proj.weight', 'model.model.language_model.layers.11.post_attention_layernorm.weight', 'model.model.language_model.layers.11.self_attn.k_proj.weight', 'model.model.language_model.layers.11.self_attn.o_proj.weight', 'model.model.language_model.layers.11.self_attn.q_proj.weight', 'model.model.language_model.layers.11.self_attn.v_proj.weight', 'model.model.language_model.layers.12.input_layernorm.weight', 'model.model.language_model.layers.12.mlp.down_proj.weight', 'model.model.language_model.layers.12.mlp.gate_proj.weight', 'model.model.language_model.layers.12.mlp.up_proj.weight', 'model.model.language_model.layers.12.post_attention_layernorm.weight', 'model.model.language_model.layers.12.self_attn.k_proj.weight', 'model.model.language_model.layers.12.self_attn.o_proj.weight', 'model.model.language_model.layers.12.self_attn.q_proj.weight', 'model.model.language_model.layers.12.self_attn.v_proj.weight', 'model.model.language_model.layers.13.input_layernorm.weight', 'model.model.language_model.layers.13.mlp.down_proj.weight', 'model.model.language_model.layers.13.mlp.gate_proj.weight', 'model.model.language_model.layers.13.mlp.up_proj.weight', 'model.model.language_model.layers.13.post_attention_layernorm.weight', 'model.model.language_model.layers.13.self_attn.k_proj.weight', 'model.model.language_model.layers.13.self_attn.o_proj.weight', 'model.model.language_model.layers.13.self_attn.q_proj.weight', 'model.model.language_model.layers.13.self_attn.v_proj.weight', 'model.model.language_model.layers.14.input_layernorm.weight', 'model.model.language_model.layers.14.mlp.down_proj.weight', 'model.model.language_model.layers.14.mlp.gate_proj.weight', 'model.model.language_model.layers.14.mlp.up_proj.weight', 'model.model.language_model.layers.14.post_attention_layernorm.weight', 'model.model.language_model.layers.14.self_attn.k_proj.weight', 'model.model.language_model.layers.14.self_attn.o_proj.weight', 'model.model.language_model.layers.14.self_attn.q_proj.weight', 'model.model.language_model.layers.14.self_attn.v_proj.weight', 'model.model.language_model.layers.15.input_layernorm.weight', 'model.model.language_model.layers.15.mlp.down_proj.weight', 'model.model.language_model.layers.15.mlp.gate_proj.weight', 'model.model.language_model.layers.15.mlp.up_proj.weight', 'model.model.language_model.layers.15.post_attention_layernorm.weight', 'model.model.language_model.layers.15.self_attn.k_proj.weight', 'model.model.language_model.layers.15.self_attn.o_proj.weight', 'model.model.language_model.layers.15.self_attn.q_proj.weight', 'model.model.language_model.layers.15.self_attn.v_proj.weight', 'model.model.language_model.layers.16.input_layernorm.weight', 'model.model.language_model.layers.16.mlp.down_proj.weight', 'model.model.language_model.layers.16.mlp.gate_proj.weight', 'model.model.language_model.layers.16.mlp.up_proj.weight', 'model.model.language_model.layers.16.post_attention_layernorm.weight', 'model.model.language_model.layers.16.self_attn.k_proj.weight', 'model.model.language_model.layers.16.self_attn.o_proj.weight', 'model.model.language_model.layers.16.self_attn.q_proj.weight', 'model.model.language_model.layers.16.self_attn.v_proj.weight', 'model.model.language_model.layers.17.input_layernorm.weight', 'model.model.language_model.layers.17.mlp.down_proj.weight', 'model.model.language_model.layers.17.mlp.gate_proj.weight', 'model.model.language_model.layers.17.mlp.up_proj.weight', 'model.model.language_model.layers.17.post_attention_layernorm.weight', 'model.model.language_model.layers.17.self_attn.k_proj.weight', 'model.model.language_model.layers.17.self_attn.o_proj.weight', 'model.model.language_model.layers.17.self_attn.q_proj.weight', 'model.model.language_model.layers.17.self_attn.v_proj.weight', 'model.model.language_model.layers.2.input_layernorm.weight', 'model.model.language_model.layers.2.mlp.down_proj.weight', 'model.model.language_model.layers.2.mlp.gate_proj.weight', 'model.model.language_model.layers.2.mlp.up_proj.weight', 'model.model.language_model.layers.2.post_attention_layernorm.weight', 'model.model.language_model.layers.2.self_attn.k_proj.weight', 'model.model.language_model.layers.2.self_attn.o_proj.weight', 'model.model.language_model.layers.2.self_attn.q_proj.weight', 'model.model.language_model.layers.2.self_attn.v_proj.weight', 'model.model.language_model.layers.3.input_layernorm.weight', 'model.model.language_model.layers.3.mlp.down_proj.weight', 'model.model.language_model.layers.3.mlp.gate_proj.weight', 'model.model.language_model.layers.3.mlp.up_proj.weight', 'model.model.language_model.layers.3.post_attention_layernorm.weight', 'model.model.language_model.layers.3.self_attn.k_proj.weight', 'model.model.language_model.layers.3.self_attn.o_proj.weight', 'model.model.language_model.layers.3.self_attn.q_proj.weight', 'model.model.language_model.layers.3.self_attn.v_proj.weight', 'model.model.language_model.layers.4.input_layernorm.weight', 'model.model.language_model.layers.4.mlp.down_proj.weight', 'model.model.language_model.layers.4.mlp.gate_proj.weight', 'model.model.language_model.layers.4.mlp.up_proj.weight', 'model.model.language_model.layers.4.post_attention_layernorm.weight', 'model.model.language_model.layers.4.self_attn.k_proj.weight', 'model.model.language_model.layers.4.self_attn.o_proj.weight', 'model.model.language_model.layers.4.self_attn.q_proj.weight', 'model.model.language_model.layers.4.self_attn.v_proj.weight', 'model.model.language_model.layers.5.input_layernorm.weight', 'model.model.language_model.layers.5.mlp.down_proj.weight', 'model.model.language_model.layers.5.mlp.gate_proj.weight', 'model.model.language_model.layers.5.mlp.up_proj.weight', 'model.model.language_model.layers.5.post_attention_layernorm.weight', 'model.model.language_model.layers.5.self_attn.k_proj.weight', 'model.model.language_model.layers.5.self_attn.o_proj.weight', 'model.model.language_model.layers.5.self_attn.q_proj.weight', 'model.model.language_model.layers.5.self_attn.v_proj.weight', 'model.model.language_model.layers.6.input_layernorm.weight', 'model.model.language_model.layers.6.mlp.down_proj.weight', 'model.model.language_model.layers.6.mlp.gate_proj.weight', 'model.model.language_model.layers.6.mlp.up_proj.weight', 'model.model.language_model.layers.6.post_attention_layernorm.weight', 'model.model.language_model.layers.6.self_attn.k_proj.weight', 'model.model.language_model.layers.6.self_attn.o_proj.weight', 'model.model.language_model.layers.6.self_attn.q_proj.weight', 'model.model.language_model.layers.6.self_attn.v_proj.weight', 'model.model.language_model.layers.7.input_layernorm.weight', 'model.model.language_model.layers.7.mlp.down_proj.weight', 'model.model.language_model.layers.7.mlp.gate_proj.weight', 'model.model.language_model.layers.7.mlp.up_proj.weight', 'model.model.language_model.layers.7.post_attention_layernorm.weight', 'model.model.language_model.layers.7.self_attn.k_proj.weight', 'model.model.language_model.layers.7.self_attn.o_proj.weight', 'model.model.language_model.layers.7.self_attn.q_proj.weight', 'model.model.language_model.layers.7.self_attn.v_proj.weight', 'model.model.language_model.layers.8.input_layernorm.weight', 'model.model.language_model.layers.8.mlp.down_proj.weight', 'model.model.language_model.layers.8.mlp.gate_proj.weight', 'model.model.language_model.layers.8.mlp.up_proj.weight', 'model.model.language_model.layers.8.post_attention_layernorm.weight', 'model.model.language_model.layers.8.self_attn.k_proj.weight', 'model.model.language_model.layers.8.self_attn.o_proj.weight', 'model.model.language_model.layers.8.self_attn.q_proj.weight', 'model.model.language_model.layers.8.self_attn.v_proj.weight', 'model.model.language_model.layers.9.input_layernorm.weight', 'model.model.language_model.layers.9.mlp.down_proj.weight', 'model.model.language_model.layers.9.mlp.gate_proj.weight', 'model.model.language_model.layers.9.mlp.up_proj.weight', 'model.model.language_model.layers.9.post_attention_layernorm.weight', 'model.model.language_model.layers.9.self_attn.k_proj.weight', 'model.model.language_model.layers.9.self_attn.o_proj.weight', 'model.model.language_model.layers.9.self_attn.q_proj.weight', 'model.model.language_model.layers.9.self_attn.v_proj.weight', 'model.model.language_model.norm.weight', 'model.model.multi_modal_projector.linear.bias', 'model.model.multi_modal_projector.linear.weight', 'model.model.vision_tower.vision_model.embeddings.patch_embedding.bias', 'model.model.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.model.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.model.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.26.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.26.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.26.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.26.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.26.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.26.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.26.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.26.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.model.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.model.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.model.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.model.vision_tower.vision_model.post_layernorm.bias', 'model.model.vision_tower.vision_model.post_layernorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ ColPali v1.3 loaded successfully on CUDA\n",
            "\n",
            "=== DETECTING EMBEDDING DIMENSION ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Raw ColPali output shape: torch.Size([1, 1026, 128])\n",
            "  → Multi-vector output: 1026 patches × 128 dimensions\n",
            "✓ Embedding dimension per patch: 128\n",
            "✓ Number of patches per image: 1026\n",
            "  Model: ColPali\n",
            "\n",
            "✓ Final config: 128D × 1026 patches\n",
            "✓ Using CLIP fallback: False\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6) Neo4j schema + Zilliz collection setup\n",
        "COLLECTION_NAME = \"nasa_bioscience_papers\"\n",
        "\n",
        "def setup_neo4j_schema():\n",
        "    with neo4j_driver.session() as session:\n",
        "        queries = [\n",
        "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (p:Publication) REQUIRE p.pub_id IS UNIQUE\",\n",
        "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (pg:Page) REQUIRE pg.page_id IS UNIQUE\",\n",
        "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (e:Entity) REQUIRE e.entity_id IS UNIQUE\",\n",
        "            \"CREATE INDEX IF NOT EXISTS FOR (e:Entity) ON (e.name)\",\n",
        "            \"CREATE INDEX IF NOT EXISTS FOR (e:Entity) ON (e.entity_type)\",\n",
        "            \"CREATE INDEX IF NOT EXISTS FOR (pg:Page) ON (pg.pub_id)\",\n",
        "        ]\n",
        "        for query in queries:\n",
        "            try:\n",
        "                session.run(query)\n",
        "                print(f\"  ✓ {query[:65]}...\")\n",
        "            except Exception as e:\n",
        "                if \"already exists\" not in str(e).lower():\n",
        "                    print(f\"  ⚠ {query[:65]}... - {e}\")\n",
        "    print(\"✓ Neo4j schema created\")\n",
        "\n",
        "def create_zilliz_collection():\n",
        "    \"\"\"Create collection with multi-vector support (one row per patch)\"\"\"\n",
        "    # Drop if exists to get a clean start\n",
        "    if utility.has_collection(COLLECTION_NAME):\n",
        "        utility.drop_collection(COLLECTION_NAME)\n",
        "        print(f\"Dropped existing collection: {COLLECTION_NAME}\")\n",
        "\n",
        "    print(f\"Creating multi-vector collection (dim={EMBEDDING_DIM})\")\n",
        "\n",
        "    # CRITICAL: Store each patch as a separate vector\n",
        "    fields = [\n",
        "        FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
        "        FieldSchema(name=\"page_id\", dtype=DataType.VARCHAR, max_length=200),\n",
        "        FieldSchema(name=\"pub_id\", dtype=DataType.VARCHAR, max_length=200),\n",
        "        FieldSchema(name=\"page_num\", dtype=DataType.INT64),\n",
        "        FieldSchema(name=\"patch_num\", dtype=DataType.INT64),  # NEW: track which patch this is\n",
        "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=EMBEDDING_DIM),\n",
        "        FieldSchema(name=\"image_path\", dtype=DataType.VARCHAR, max_length=500),\n",
        "    ]\n",
        "\n",
        "    schema = CollectionSchema(fields, description=\"NASA Bioscience Papers (Multi-Vector)\")\n",
        "    collection = Collection(name=COLLECTION_NAME, schema=schema)\n",
        "\n",
        "    index_params = {\n",
        "        \"metric_type\": \"IP\",\n",
        "        \"index_type\": \"AUTOINDEX\",\n",
        "        \"params\": {}\n",
        "    }\n",
        "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
        "    print(f\"✓ Created collection: {COLLECTION_NAME}\")\n",
        "    print(f\"  Dimension: {EMBEDDING_DIM}\")\n",
        "    print(f\"  Storage mode: Multi-vector (1 row per patch)\")\n",
        "    return collection\n",
        "\n",
        "print(\"\\n=== SETTING UP NEO4J ===\")\n",
        "setup_neo4j_schema()\n",
        "\n",
        "print(\"\\n=== SETTING UP ZILLIZ ===\")\n",
        "zilliz_collection = create_zilliz_collection()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-04T15:02:16.258Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IANH4m65v8YQ",
        "outputId": "af0c9cb3-faf4-40ce-af28-ffb04deca952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== SETTING UP NEO4J ===\n",
            "  ✓ CREATE CONSTRAINT IF NOT EXISTS FOR (p:Publication) REQUIRE p.pub...\n",
            "  ✓ CREATE CONSTRAINT IF NOT EXISTS FOR (pg:Page) REQUIRE pg.page_id ...\n",
            "  ✓ CREATE CONSTRAINT IF NOT EXISTS FOR (e:Entity) REQUIRE e.entity_i...\n",
            "  ✓ CREATE INDEX IF NOT EXISTS FOR (e:Entity) ON (e.name)...\n",
            "  ✓ CREATE INDEX IF NOT EXISTS FOR (e:Entity) ON (e.entity_type)...\n",
            "  ✓ CREATE INDEX IF NOT EXISTS FOR (pg:Page) ON (pg.pub_id)...\n",
            "✓ Neo4j schema created\n",
            "\n",
            "=== SETTING UP ZILLIZ ===\n",
            "Creating multi-vector collection (dim=128)\n",
            "✓ Created collection: nasa_bioscience_papers\n",
            "  Dimension: 128\n",
            "  Storage mode: Multi-vector (1 row per patch)\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7) Utilities: PDF→images, OCR, embeddings, NER, relations\n",
        "def cleanup_temp_files(pub_id: str):\n",
        "    temp_dir = Path(WORKING_DIR) / \"pages\" / pub_id\n",
        "    if temp_dir.exists():\n",
        "        try:\n",
        "            shutil.rmtree(temp_dir)\n",
        "            print(f\"  ✓ Cleaned temp files for {pub_id}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ⚠ Could not clean temp files: {e}\")\n",
        "\n",
        "def pdf_to_images(pdf_path: str, dpi: int = 150) -> List[str]:\n",
        "    out_dir = Path(WORKING_DIR) / \"pages\" / Path(pdf_path).stem\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        images = convert_from_path(pdf_path, dpi=dpi, thread_count=2)\n",
        "        paths = []\n",
        "        for i, img in enumerate(images, start=1):\n",
        "            img_path = out_dir / f\"page_{i:03d}.png\"\n",
        "            img.save(img_path, format=\"PNG\", optimize=True)\n",
        "            paths.append(str(img_path))\n",
        "            img.close()\n",
        "        del images\n",
        "        gc.collect()\n",
        "        return paths\n",
        "    except Exception as e:\n",
        "        print(f\"  ⚠ Error converting PDF {pdf_path}: {e}\")\n",
        "        raise\n",
        "\n",
        "def extract_text_ocr(image_path: str) -> str:\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        text = pytesseract.image_to_string(img, lang=\"eng\").strip()\n",
        "        img.close()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"  ⚠ OCR error on {image_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def embed_images_colpali(image_paths: List[str], batch_size: int = 2) -> List[np.ndarray]:\n",
        "    \"\"\"\n",
        "    Generate multi-vector embeddings for ColPali.\n",
        "    Returns: List of arrays, each with shape [num_patches, embedding_dim]\n",
        "    \"\"\"\n",
        "    all_embeddings = []\n",
        "\n",
        "    for i in range(0, len(image_paths), batch_size):\n",
        "        batch = image_paths[i:i+batch_size]\n",
        "        images = []\n",
        "\n",
        "        try:\n",
        "            images = [Image.open(p).convert(\"RGB\") for p in batch]\n",
        "\n",
        "            # Process images with proper tokens\n",
        "            if USING_CLIP_FALLBACK:\n",
        "                inputs = colpali_processor(images=images, return_tensors=\"pt\", padding=True)\n",
        "            else:\n",
        "                texts = [\"<image>\" for _ in images]\n",
        "                inputs = colpali_processor(\n",
        "                    text=texts,\n",
        "                    images=images,\n",
        "                    return_tensors=\"pt\",\n",
        "                    padding=True\n",
        "                )\n",
        "\n",
        "            if device == \"cuda\":\n",
        "                inputs = {k: (v.to(device) if hasattr(v, \"to\") else v) for k, v in inputs.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                if USING_CLIP_FALLBACK:\n",
        "                    emb = colpali_model.get_image_features(**inputs)\n",
        "                    # CLIP: single vector per image [batch, dim]\n",
        "                    emb = emb.detach().cpu().float().numpy()\n",
        "                    # Reshape to [batch, 1, dim] for consistency\n",
        "                    emb = emb[:, np.newaxis, :]\n",
        "                else:\n",
        "                    out = colpali_model(**inputs)\n",
        "\n",
        "                    # Extract embeddings from ColPali output\n",
        "                    if hasattr(out, \"last_hidden_state\"):\n",
        "                        emb = out.last_hidden_state\n",
        "                    elif hasattr(out, \"embeddings\"):\n",
        "                        emb = out.embeddings\n",
        "                    elif isinstance(out, torch.Tensor):\n",
        "                        emb = out\n",
        "                    else:\n",
        "                        emb = out[0] if isinstance(out, (tuple, list)) else out\n",
        "\n",
        "                    # Keep multi-vector format [batch, num_patches, dim]\n",
        "                    emb = emb.detach().cpu().float().numpy()\n",
        "\n",
        "                    if len(emb.shape) == 2:\n",
        "                        # Single vector - reshape to [batch, 1, dim]\n",
        "                        emb = emb[:, np.newaxis, :]\n",
        "                    elif len(emb.shape) != 3:\n",
        "                        raise ValueError(f\"Unexpected embedding shape: {emb.shape}\")\n",
        "\n",
        "            # Add each image's multi-vector embedding\n",
        "            for img_emb in emb:\n",
        "                # img_emb has shape [num_patches, dim]\n",
        "                all_embeddings.append(img_emb)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ⚠ Embedding error for batch {i//batch_size}: {e}\")\n",
        "            print(traceback.format_exc())\n",
        "            # Fallback: single zero vector per image\n",
        "            for _ in batch:\n",
        "                all_embeddings.append(np.zeros((1, EMBEDDING_DIM), dtype=np.float32))\n",
        "\n",
        "        finally:\n",
        "            # Cleanup\n",
        "            for img in images:\n",
        "                try:\n",
        "                    img.close()\n",
        "                except:\n",
        "                    pass\n",
        "            del images\n",
        "            if 'inputs' in locals():\n",
        "                del inputs\n",
        "            if 'out' in locals():\n",
        "                del out\n",
        "            if 'emb' in locals():\n",
        "                del emb\n",
        "            gc.collect()\n",
        "            if device == \"cuda\":\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    return all_embeddings\n",
        "\n",
        "def extract_entities(text: str) -> List[Dict]:\n",
        "    try:\n",
        "        doc = nlp(text[:10000])  # limit for speed\n",
        "        return [{\"text\": e.text, \"label\": e.label_, \"start\": e.start_char, \"end\": e.end_char}\n",
        "                for e in doc.ents]\n",
        "    except Exception as e:\n",
        "        print(f\"  ⚠ Entity extraction error: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_relations(text: str, entities: List[Dict]) -> List[Dict]:\n",
        "    relations = []\n",
        "    patterns = {\n",
        "        \"UPREGULATES\": [\"upregulate\", \"increase\", \"enhance\", \"promote\", \"stimulate\"],\n",
        "        \"DOWNREGULATES\": [\"downregulate\", \"decrease\", \"inhibit\", \"suppress\", \"reduce\"],\n",
        "        \"INTERACTS_WITH\": [\"interact\", \"bind\", \"associate\", \"complex\"],\n",
        "        \"METABOLIZES\": [\"metabolize\", \"convert\", \"transform\", \"process\"],\n",
        "    }\n",
        "    try:\n",
        "        sentences = text.split('.')[:30]\n",
        "        for sent in sentences:\n",
        "            sent_lower = sent.lower()\n",
        "            ents = [e for e in entities if e[\"text\"].lower() in sent_lower]\n",
        "            if len(ents) >= 2:\n",
        "                for rel_type, keywords in patterns.items():\n",
        "                    if any(kw in sent_lower for kw in keywords):\n",
        "                        relations.append({\n",
        "                            \"subject\": ents[0][\"text\"],\n",
        "                            \"relation\": rel_type,\n",
        "                            \"object\": ents[1][\"text\"],\n",
        "                            \"evidence\": sent[:200]\n",
        "                        })\n",
        "                        break\n",
        "                if len(relations) >= 20:\n",
        "                    break\n",
        "    except Exception as e:\n",
        "        print(f\"  ⚠ Relation extraction error: {e}\")\n",
        "    return relations"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-04T15:02:16.258Z"
        },
        "id": "sgWbun35v8YR"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 8) Neo4j ingestion helpers\n",
        "def ingest_publication(pub_id: str, metadata: Dict):\n",
        "    try:\n",
        "        with neo4j_driver.session() as session:\n",
        "            session.run(\"\"\"\n",
        "                MERGE (p:Publication {pub_id: $pub_id})\n",
        "                SET p.total_pages = $pages,\n",
        "                    p.processed_at = datetime()\n",
        "            \"\"\", {\"pub_id\": pub_id, \"pages\": metadata.get(\"total_pages\", 0)})\n",
        "    except Exception as e:\n",
        "        print(f\"  ⚠ Publication ingestion error: {e}\")\n",
        "\n",
        "def ingest_page(page_id: str, pub_id: str, page_num: int, text: str):\n",
        "    try:\n",
        "        with neo4j_driver.session() as session:\n",
        "            truncated_text = text[:30000] if text else \"\"\n",
        "            session.run(\"\"\"\n",
        "                MERGE (pg:Page {page_id: $page_id})\n",
        "                SET pg.pub_id = $pub_id,\n",
        "                    pg.page_num = $page_num,\n",
        "                    pg.text = $text,\n",
        "                    pg.text_length = $text_length\n",
        "                WITH pg\n",
        "                MATCH (p:Publication {pub_id: $pub_id})\n",
        "                MERGE (pg)-[:PART_OF]->(p)\n",
        "            \"\"\", {\n",
        "                \"page_id\": page_id,\n",
        "                \"pub_id\": pub_id,\n",
        "                \"page_num\": page_num,\n",
        "                \"text\": truncated_text,\n",
        "                \"text_length\": len(text)\n",
        "            })\n",
        "    except Exception as e:\n",
        "        print(f\"  ⚠ Page ingestion error: {e}\")\n",
        "\n",
        "def ingest_entity(entity: Dict, page_id: str):\n",
        "    try:\n",
        "        entity_id = f\"{entity['label']}_{abs(hash(entity['text'])) % 10**9}\"\n",
        "        with neo4j_driver.session() as session:\n",
        "            session.run(\"\"\"\n",
        "                MERGE (e:Entity {entity_id: $eid})\n",
        "                SET e.name = $name, e.entity_type = $type\n",
        "                WITH e\n",
        "                MATCH (pg:Page {page_id: $page_id})\n",
        "                MERGE (e)-[:MENTIONED_IN]->(pg)\n",
        "            \"\"\", {\n",
        "                \"eid\": entity_id,\n",
        "                \"name\": entity[\"text\"],\n",
        "                \"type\": entity[\"label\"],\n",
        "                \"page_id\": page_id\n",
        "            })\n",
        "    except Exception:\n",
        "        pass  # tolerate per-entity failures\n",
        "\n",
        "def ingest_relation(rel: Dict, page_id: str, pub_id: str):\n",
        "    try:\n",
        "        with neo4j_driver.session() as session:\n",
        "            session.run(\"\"\"\n",
        "                MERGE (s:Entity {name: $subj})\n",
        "                MERGE (o:Entity {name: $obj})\n",
        "                MERGE (s)-[r:RELATES {relation_type: $rel, source_pub: $pub}]->(o)\n",
        "                SET r.evidence = $evidence\n",
        "            \"\"\", {\n",
        "                \"subj\": rel[\"subject\"],\n",
        "                \"obj\": rel[\"object\"],\n",
        "                \"rel\": rel[\"relation\"],\n",
        "                \"pub\": pub_id,\n",
        "                \"evidence\": rel[\"evidence\"]\n",
        "            })\n",
        "    except Exception:\n",
        "        pass"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-04T15:02:16.258Z"
        },
        "id": "6kkd54Bsv8YS"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 9) Zilliz insertion helper (with explicit fields)\n",
        "def insert_to_zilliz(data: List[Dict]):\n",
        "    \"\"\"Insert multi-vector embeddings (one row per patch)\"\"\"\n",
        "    if not data:\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        zilliz_collection.load()\n",
        "\n",
        "        # Flatten: each patch becomes a separate row\n",
        "        rows_to_insert = []\n",
        "\n",
        "        for item in data:\n",
        "            embedding = item[\"embedding\"]  # shape: [num_patches, dim]\n",
        "            num_patches = embedding.shape[0]\n",
        "\n",
        "            for patch_idx in range(num_patches):\n",
        "                rows_to_insert.append({\n",
        "                    \"page_id\": item[\"page_id\"],\n",
        "                    \"pub_id\": item[\"pub_id\"],\n",
        "                    \"page_num\": item[\"page_num\"],\n",
        "                    \"patch_num\": patch_idx,\n",
        "                    \"embedding\": embedding[patch_idx].tolist(),\n",
        "                    \"image_path\": item[\"image_path\"]\n",
        "                })\n",
        "\n",
        "        # Insert in batches\n",
        "        batch_size = 100\n",
        "        for i in range(0, len(rows_to_insert), batch_size):\n",
        "            batch = rows_to_insert[i:i+batch_size]\n",
        "\n",
        "            insert_data = [\n",
        "                [d[\"page_id\"] for d in batch],\n",
        "                [d[\"pub_id\"] for d in batch],\n",
        "                [d[\"page_num\"] for d in batch],\n",
        "                [d[\"patch_num\"] for d in batch],\n",
        "                [d[\"embedding\"] for d in batch],\n",
        "                [d[\"image_path\"] for d in batch],\n",
        "            ]\n",
        "\n",
        "            zilliz_collection.insert(insert_data)\n",
        "\n",
        "        zilliz_collection.flush()\n",
        "        print(f\"  ✓ Inserted {len(rows_to_insert)} patch vectors ({len(data)} pages) to Zilliz\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ⚠ Zilliz insertion error: {e}\")\n",
        "        print(traceback.format_exc())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-04T15:02:16.258Z"
        },
        "id": "NOhAK8Oqv8YS"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 10) PDF processing pipeline\n",
        "def process_pdf(pdf_path: str) -> bool:\n",
        "    pub_id = Path(pdf_path).stem\n",
        "    print(f\"\\n{'='*60}\\nProcessing: {pub_id}\\n{'='*60}\")\n",
        "    try:\n",
        "        print(\"→ Converting to images...\")\n",
        "        images = pdf_to_images(pdf_path, dpi=DPI)\n",
        "        print(f\"  {len(images)} pages\")\n",
        "\n",
        "        print(\"→ Generating embeddings...\")\n",
        "        embeddings = embed_images_colpali(images, batch_size=BATCH_SIZE)\n",
        "        if len(embeddings) != len(images):\n",
        "            print(f\"  ⚠ Embedding count mismatch: {len(embeddings)} vs {len(images)}\")\n",
        "            return False\n",
        "\n",
        "        ingest_publication(pub_id, {\"total_pages\": len(images)})\n",
        "\n",
        "        zilliz_data = []\n",
        "        for i, (img_path, emb) in enumerate(zip(images, embeddings), start=1):\n",
        "            page_id = f\"{pub_id}_p{i}\"\n",
        "            print(f\"  Page {i}/{len(images)}\", end=\"\")\n",
        "\n",
        "            text = extract_text_ocr(img_path)\n",
        "            ingest_page(page_id, pub_id, i, text)\n",
        "\n",
        "            if text:\n",
        "                entities = extract_entities(text)\n",
        "                print(f\" - {len(entities)} entities\", end=\"\")\n",
        "                for entity in entities[:30]:\n",
        "                    ingest_entity(entity, page_id)\n",
        "                if i % 3 == 1:\n",
        "                    relations = extract_relations(text, entities)\n",
        "                    print(f\" - {len(relations)} relations\", end=\"\")\n",
        "                    for rel in relations:\n",
        "                        ingest_relation(rel, page_id, pub_id)\n",
        "\n",
        "            print()\n",
        "\n",
        "            zilliz_data.append({\n",
        "                \"page_id\": page_id,\n",
        "                \"pub_id\": pub_id,\n",
        "                \"page_num\": i,\n",
        "                \"embedding\": emb,\n",
        "                \"image_path\": img_path\n",
        "            })\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                gc.collect()\n",
        "                if device == \"cuda\":\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "        print(\"→ Inserting to Zilliz...\")\n",
        "        insert_to_zilliz(zilliz_data)\n",
        "\n",
        "        cleanup_temp_files(pub_id)\n",
        "        print(f\"✓ Completed: {pub_id}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ ERROR processing {pub_id}: {e}\")\n",
        "        traceback.print_exc()\n",
        "        cleanup_temp_files(pub_id)\n",
        "        return False\n",
        "\n",
        "def process_all(pdf_dir: str, limit: Optional[int] = None):\n",
        "    pdfs = sorted(list(Path(pdf_dir).glob(\"*.pdf\")))\n",
        "    if limit:\n",
        "        pdfs = pdfs[:limit]\n",
        "\n",
        "    print(f\"\\n{'='*60}\\nPROCESSING {len(pdfs)} PDFs\\nTest Mode: {TEST_MODE}\\n{'='*60}\")\n",
        "    success_count = 0\n",
        "    failed_pdfs = []\n",
        "\n",
        "    for i, pdf in enumerate(pdfs, 1):\n",
        "        print(f\"\\n[{i}/{len(pdfs)}] - {pdf.name}\")\n",
        "        try:\n",
        "            if process_pdf(str(pdf)):\n",
        "                success_count += 1\n",
        "            else:\n",
        "                failed_pdfs.append(pdf.name)\n",
        "        except Exception as e:\n",
        "            print(f\"CRITICAL ERROR: {e}\")\n",
        "            failed_pdfs.append(pdf.name)\n",
        "\n",
        "        gc.collect()\n",
        "        if device == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"\\n{'='*60}\\nPROCESSING SUMMARY\\n{'='*60}\")\n",
        "    print(f\"Successful: {success_count}/{len(pdfs)}\")\n",
        "    if failed_pdfs:\n",
        "        print(\"Failed PDFs:\")\n",
        "        for pdf_name in failed_pdfs:\n",
        "            print(f\"  - {pdf_name}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-04T15:02:16.258Z"
        },
        "id": "Ufr6N5bQv8YT"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 11) Run the ingestion pipeline\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING INGESTION PIPELINE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Mode: {'TEST' if TEST_MODE else 'PRODUCTION'}\")\n",
        "print(f\"Limit: {LIMIT if LIMIT else 'No limit'}\")\n",
        "print(f\"Dataset: {DATASET_PATH}\")\n",
        "\n",
        "if not Path(DATASET_PATH).exists():\n",
        "    print(f\"\\n✗ ERROR: Dataset path not found: {DATASET_PATH}\")\n",
        "    print(\"Please check the path and try again.\")\n",
        "else:\n",
        "    pdf_count = len(list(Path(DATASET_PATH).glob(\"*.pdf\")))\n",
        "    print(f\"Found {pdf_count} PDFs in dataset\")\n",
        "    process_all(DATASET_PATH, limit=LIMIT)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"INGESTION COMPLETE\")\n",
        "    print(\"=\"*60)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-04T15:02:16.258Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onxCm6L4v8YT",
        "outputId": "f703e5b4-4f0c-4b9e-9273-ffe9d1b5b7e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STARTING INGESTION PIPELINE\n",
            "============================================================\n",
            "Mode: TEST\n",
            "Limit: 30\n",
            "Dataset: /content/pdfs\n",
            "Found 30 PDFs in dataset\n",
            "\n",
            "============================================================\n",
            "PROCESSING 30 PDFs\n",
            "Test Mode: True\n",
            "============================================================\n",
            "\n",
            "[1/30] - 10528_2010_Article_9411.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 10528_2010_Article_9411\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  23 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/23 - 28 entities - 1 relations\n",
            "  Page 2/23 - 74 entities\n",
            "  Page 3/23 - 39 entities\n",
            "  Page 4/23 - 29 entities - 0 relations\n",
            "  Page 5/23 - 17 entities\n",
            "  Page 6/23 - 34 entities\n",
            "  Page 7/23 - 13 entities - 1 relations\n",
            "  Page 8/23 - 37 entities\n",
            "  Page 9/23 - 55 entities\n",
            "  Page 10/23 - 21 entities - 2 relations\n",
            "  Page 11/23 - 31 entities\n",
            "  Page 12/23 - 39 entities\n",
            "  Page 13/23 - 37 entities - 7 relations\n",
            "  Page 14/23 - 34 entities\n",
            "  Page 15/23 - 27 entities\n",
            "  Page 16/23 - 42 entities - 4 relations\n",
            "  Page 17/23 - 16 entities\n",
            "  Page 18/23 - 44 entities\n",
            "  Page 19/23 - 46 entities - 6 relations\n",
            "  Page 20/23 - 97 entities\n",
            "  Page 21/23 - 94 entities\n",
            "  Page 22/23 - 92 entities - 3 relations\n",
            "  Page 23/23 - 5 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 23598 patch vectors (23 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 10528_2010_Article_9411\n",
            "✓ Completed: 10528_2010_Article_9411\n",
            "\n",
            "[2/30] - 10552_2010_Article_9684.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 10552_2010_Article_9684\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  10 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/10 - 62 entities - 1 relations\n",
            "  Page 2/10 - 93 entities\n",
            "  Page 3/10 - 55 entities\n",
            "  Page 4/10 - 50 entities - 7 relations\n",
            "  Page 5/10 - 30 entities\n",
            "  Page 6/10 - 37 entities\n",
            "  Page 7/10 - 62 entities - 0 relations\n",
            "  Page 8/10 - 113 entities\n",
            "  Page 9/10 - 174 entities\n",
            "  Page 10/10 - 64 entities - 1 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 10260 patch vectors (10 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 10552_2010_Article_9684\n",
            "✓ Completed: 10552_2010_Article_9684\n",
            "\n",
            "[3/30] - 10616_2015_Article_9843.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 10616_2015_Article_9843\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  13 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/13 - 53 entities - 2 relations\n",
            "  Page 2/13 - 76 entities\n",
            "  Page 3/13 - 83 entities\n",
            "  Page 4/13 - 57 entities - 1 relations\n",
            "  Page 5/13 - 78 entities\n",
            "  Page 6/13 - 35 entities\n",
            "  Page 7/13 - 42 entities - 1 relations\n",
            "  Page 8/13 - 61 entities\n",
            "  Page 9/13 - 42 entities\n",
            "  Page 10/13 - 66 entities - 4 relations\n",
            "  Page 11/13 - 68 entities\n",
            "  Page 12/13 - 153 entities\n",
            "  Page 13/13 - 148 entities - 5 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 13338 patch vectors (13 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 10616_2015_Article_9843\n",
            "✓ Completed: 10616_2015_Article_9843\n",
            "\n",
            "[4/30] - 11095_2022_Article_3191.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 11095_2022_Article_3191\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  11 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/11 - 49 entities - 0 relations\n",
            "  Page 2/11 - 79 entities\n",
            "  Page 3/11 - 50 entities\n",
            "  Page 4/11 - 49 entities - 0 relations\n",
            "  Page 5/11 - 56 entities\n",
            "  Page 6/11 - 35 entities\n",
            "  Page 7/11 - 51 entities - 0 relations\n",
            "  Page 8/11 - 48 entities\n",
            "  Page 9/11 - 28 entities\n",
            "  Page 10/11 - 137 entities - 0 relations\n",
            "  Page 11/11 - 15 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 11286 patch vectors (11 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 11095_2022_Article_3191\n",
            "✓ Completed: 11095_2022_Article_3191\n",
            "\n",
            "[5/30] - 12217_2017_Article_9588.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 12217_2017_Article_9588\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  14 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/14 - 29 entities - 3 relations\n",
            "  Page 2/14 - 50 entities\n",
            "  Page 3/14 - 46 entities\n",
            "  Page 4/14 - 19 entities - 1 relations\n",
            "  Page 5/14 - 75 entities\n",
            "  Page 6/14 - 32 entities\n",
            "  Page 7/14 - 54 entities - 12 relations\n",
            "  Page 8/14 - 28 entities\n",
            "  Page 9/14 - 41 entities\n",
            "  Page 10/14 - 37 entities - 0 relations\n",
            "  Page 11/14 - 61 entities\n",
            "  Page 12/14 - 55 entities\n",
            "  Page 13/14 - 160 entities - 0 relations\n",
            "  Page 14/14 - 99 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 14364 patch vectors (14 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 12217_2017_Article_9588\n",
            "✓ Completed: 12217_2017_Article_9588\n",
            "\n",
            "[6/30] - 12864_2018_Article_4948.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 12864_2018_Article_4948\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  14 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/14 - 20 entities - 2 relations\n",
            "  Page 2/14 - 26 entities\n",
            "  Page 3/14 - 19 entities\n",
            "  Page 4/14 - 29 entities - 5 relations\n",
            "  Page 5/14 - 42 entities\n",
            "  Page 6/14 - 34 entities\n",
            "  Page 7/14 - 48 entities - 12 relations\n",
            "  Page 8/14 - 51 entities\n",
            "  Page 9/14 - 51 entities\n",
            "  Page 10/14 - 23 entities - 0 relations\n",
            "  Page 11/14 - 29 entities\n",
            "  Page 12/14 - 35 entities\n",
            "  Page 13/14 - 124 entities - 0 relations\n",
            "  Page 14/14 - 29 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 14364 patch vectors (14 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 12864_2018_Article_4948\n",
            "✓ Completed: 12864_2018_Article_4948\n",
            "\n",
            "[7/30] - 12864_2025_Article_11426.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 12864_2025_Article_11426\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  15 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/15 - 44 entities - 3 relations\n",
            "  Page 2/15 - 59 entities\n",
            "  Page 3/15 - 28 entities\n",
            "  Page 4/15 - 78 entities - 4 relations\n",
            "  Page 5/15 - 30 entities\n",
            "  Page 6/15 - 69 entities\n",
            "  Page 7/15 - 45 entities - 7 relations\n",
            "  Page 8/15 - 22 entities\n",
            "  Page 9/15 - 22 entities\n",
            "  Page 10/15 - 109 entities - 7 relations\n",
            "  Page 11/15 - 69 entities\n",
            "  Page 12/15 - 46 entities\n",
            "  Page 13/15 - 81 entities - 2 relations\n",
            "  Page 14/15 - 165 entities\n",
            "  Page 15/15 - 152 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 15390 patch vectors (15 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 12864_2025_Article_11426\n",
            "✓ Completed: 12864_2025_Article_11426\n",
            "\n",
            "[8/30] - 12866_2018_Article_1325.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 12866_2018_Article_1325\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  13 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/13 - 19 entities - 2 relations\n",
            "  Page 2/13 - 50 entities\n",
            "  Page 3/13 - 52 entities\n",
            "  Page 4/13 - 54 entities - 0 relations\n",
            "  Page 5/13 - 31 entities\n",
            "  Page 6/13 - 47 entities\n",
            "  Page 7/13 - 55 entities - 2 relations\n",
            "  Page 8/13 - 56 entities\n",
            "  Page 9/13 - 45 entities\n",
            "  Page 10/13 - 51 entities - 0 relations\n",
            "  Page 11/13 - 44 entities\n",
            "  Page 12/13 - 134 entities\n",
            "  Page 13/13 - 70 entities - 0 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 13338 patch vectors (13 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 12866_2018_Article_1325\n",
            "✓ Completed: 12866_2018_Article_1325\n",
            "\n",
            "[9/30] - 12866_2022_Article_2614.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 12866_2022_Article_2614\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  20 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/20 - 22 entities - 3 relations\n",
            "  Page 2/20 - 59 entities\n",
            "  Page 3/20 - 36 entities\n",
            "  Page 4/20 - 76 entities - 5 relations\n",
            "  Page 5/20 - 105 entities\n",
            "  Page 6/20 - 47 entities\n",
            "  Page 7/20 - 33 entities - 1 relations\n",
            "  Page 8/20 - 31 entities\n",
            "  Page 9/20 - 52 entities\n",
            "  Page 10/20 - 14 entities - 0 relations\n",
            "  Page 11/20 - 32 entities\n",
            "  Page 12/20 - 28 entities\n",
            "  Page 13/20 - 59 entities - 5 relations\n",
            "  Page 14/20 - 69 entities\n",
            "  Page 15/20 - 50 entities\n",
            "  Page 16/20 - 31 entities - 1 relations\n",
            "  Page 17/20 - 55 entities\n",
            "  Page 18/20 - 103 entities\n",
            "  Page 19/20 - 174 entities - 0 relations\n",
            "  Page 20/20 - 35 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 20520 patch vectors (20 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 12866_2022_Article_2614\n",
            "✓ Completed: 12866_2022_Article_2614\n",
            "\n",
            "[10/30] - 12870_2017_Article_1024 (1).pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 12870_2017_Article_1024 (1)\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  12 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/12 - 47 entities - 9 relations\n",
            "  Page 2/12 - 86 entities\n",
            "  Page 3/12 - 57 entities\n",
            "  Page 4/12 - 45 entities - 3 relations\n",
            "  Page 5/12 - 62 entities\n",
            "  Page 6/12 - 46 entities\n",
            "  Page 7/12 - 45 entities - 3 relations\n",
            "  Page 8/12 - 65 entities\n",
            "  Page 9/12 - 58 entities\n",
            "  Page 10/12 - 121 entities - 13 relations\n",
            "  Page 11/12 - 134 entities\n",
            "  Page 12/12 - 183 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 12312 patch vectors (12 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 12870_2017_Article_1024 (1)\n",
            "✓ Completed: 12870_2017_Article_1024 (1)\n",
            "\n",
            "[11/30] - 12870_2017_Article_1024.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 12870_2017_Article_1024\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  12 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/12 - 47 entities - 9 relations\n",
            "  Page 2/12 - 86 entities\n",
            "  Page 3/12 - 57 entities\n",
            "  Page 4/12 - 45 entities - 3 relations\n",
            "  Page 5/12 - 62 entities\n",
            "  Page 6/12 - 46 entities\n",
            "  Page 7/12 - 45 entities - 3 relations\n",
            "  Page 8/12 - 65 entities\n",
            "  Page 9/12 - 58 entities\n",
            "  Page 10/12 - 121 entities - 13 relations\n",
            "  Page 11/12 - 134 entities\n",
            "  Page 12/12 - 183 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 12312 patch vectors (12 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 12870_2017_Article_1024\n",
            "✓ Completed: 12870_2017_Article_1024\n",
            "\n",
            "[12/30] - 12870_2017_Article_975.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 12870_2017_Article_975\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  16 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/16 - 23 entities - 3 relations\n",
            "  Page 2/16 - 61 entities\n",
            "  Page 3/16 - 51 entities\n",
            "  Page 4/16 - 34 entities - 2 relations\n",
            "  Page 5/16 - 93 entities\n",
            "  Page 6/16 - 32 entities\n",
            "  Page 7/16 - 32 entities - 1 relations\n",
            "  Page 8/16 - 58 entities\n",
            "  Page 9/16 - 65 entities\n",
            "  Page 10/16 - 71 entities - 7 relations\n",
            "  Page 11/16 - 46 entities\n",
            "  Page 12/16 - 69 entities\n",
            "  Page 13/16 - 50 entities - 0 relations\n",
            "  Page 14/16 - 133 entities\n",
            "  Page 15/16 - 198 entities\n",
            "  Page 16/16 - 115 entities - 1 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 16416 patch vectors (16 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 12870_2017_Article_975\n",
            "✓ Completed: 12870_2017_Article_975\n",
            "\n",
            "[13/30] - 12870_2020_Article_2392.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 12870_2020_Article_2392\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  16 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/16 - 20 entities - 0 relations\n",
            "  Page 2/16 - 24 entities\n",
            "  Page 3/16 - 28 entities\n",
            "  Page 4/16 - 17 entities - 0 relations\n",
            "  Page 5/16 - 97 entities\n",
            "  Page 6/16 - 21 entities\n",
            "  Page 7/16 - 57 entities - 2 relations\n",
            "  Page 8/16 - 47 entities\n",
            "  Page 9/16 - 63 entities\n",
            "  Page 10/16 - 49 entities - 2 relations\n",
            "  Page 11/16 - 41 entities\n",
            "  Page 12/16 - 61 entities\n",
            "  Page 13/16 - 34 entities - 1 relations\n",
            "  Page 14/16 - 16 entities\n",
            "  Page 15/16 - 126 entities\n",
            "  Page 16/16 - 88 entities - 0 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 16416 patch vectors (16 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 12870_2020_Article_2392\n",
            "✓ Completed: 12870_2020_Article_2392\n",
            "\n",
            "[14/30] - 12985_2024_Article_2374.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 12985_2024_Article_2374\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  15 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/15 - 31 entities - 5 relations\n",
            "  Page 2/15 - 88 entities\n",
            "  Page 3/15 - 65 entities\n",
            "  Page 4/15 - 67 entities - 0 relations\n",
            "  Page 5/15 - 28 entities\n",
            "  Page 6/15 - 62 entities\n",
            "  Page 7/15 - 29 entities - 3 relations\n",
            "  Page 8/15 - 63 entities\n",
            "  Page 9/15 - 62 entities\n",
            "  Page 10/15 - 49 entities - 2 relations\n",
            "  Page 11/15 - 76 entities\n",
            "  Page 12/15 - 17 entities\n",
            "  Page 13/15 - 59 entities - 8 relations\n",
            "  Page 14/15 - 197 entities\n",
            "  Page 15/15 - 6 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 15390 patch vectors (15 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 12985_2024_Article_2374\n",
            "✓ Completed: 12985_2024_Article_2374\n",
            "\n",
            "[15/30] - 13059_2022_Article_2824.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 13059_2022_Article_2824\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  19 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/19 - 22 entities - 2 relations\n",
            "  Page 2/19 - 31 entities\n",
            "  Page 3/19 - 19 entities\n",
            "  Page 4/19 - 19 entities - 2 relations\n",
            "  Page 5/19 - 15 entities\n",
            "  Page 6/19 - 24 entities\n",
            "  Page 7/19 - 34 entities - 2 relations\n",
            "  Page 8/19 - 21 entities\n",
            "  Page 9/19 - 35 entities\n",
            "  Page 10/19 - 41 entities - 0 relations\n",
            "  Page 11/19 - 28 entities\n",
            "  Page 12/19 - 41 entities\n",
            "  Page 13/19 - 47 entities - 8 relations\n",
            "  Page 14/19 - 34 entities\n",
            "  Page 15/19 - 15 entities\n",
            "  Page 16/19 - 74 entities - 1 relations\n",
            "  Page 17/19 - 136 entities\n",
            "  Page 18/19 - 117 entities\n",
            "  Page 19/19 - 97 entities - 0 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 19494 patch vectors (19 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 13059_2022_Article_2824\n",
            "✓ Completed: 13059_2022_Article_2824\n",
            "\n",
            "[16/30] - 1582-10.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 1582-10\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  10 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/10 - 46 entities - 1 relations\n",
            "  Page 2/10 - 47 entities\n",
            "  Page 3/10 - 32 entities\n",
            "  Page 4/10 - 58 entities - 0 relations\n",
            "  Page 5/10 - 46 entities\n",
            "  Page 6/10 - 53 entities\n",
            "  Page 7/10 - 75 entities - 1 relations\n",
            "  Page 8/10 - 61 entities\n",
            "  Page 9/10 - 58 entities\n",
            "  Page 10/10 - 116 entities - 0 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 10260 patch vectors (10 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 1582-10\n",
            "✓ Completed: 1582-10\n",
            "\n",
            "[17/30] - 1707.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 1707\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  11 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/11 - 97 entities - 5 relations\n",
            "  Page 2/11 - 121 entities\n",
            "  Page 3/11 - 70 entities\n",
            "  Page 4/11 - 93 entities - 5 relations\n",
            "  Page 5/11 - 107 entities\n",
            "  Page 6/11 - 72 entities\n",
            "  Page 7/11 - 120 entities - 4 relations\n",
            "  Page 8/11 - 117 entities\n",
            "  Page 9/11 - 122 entities\n",
            "  Page 10/11 - 177 entities - 2 relations\n",
            "  Page 11/11 - 129 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 11286 patch vectors (11 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 1707\n",
            "✓ Completed: 1707\n",
            "\n",
            "[18/30] - 1749-799X-6-8.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 1749-799X-6-8\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  8 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/8 - 74 entities - 5 relations\n",
            "  Page 2/8 - 77 entities\n",
            "  Page 3/8 - 75 entities\n",
            "  Page 4/8 - 64 entities - 10 relations\n",
            "  Page 5/8 - 71 entities\n",
            "  Page 6/8 - 66 entities\n",
            "  Page 7/8 - 172 entities - 2 relations\n",
            "  Page 8/8 - 14 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 8208 patch vectors (8 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 1749-799X-6-8\n",
            "✓ Completed: 1749-799X-6-8\n",
            "\n",
            "[19/30] - 2044-5040-4-13.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 2044-5040-4-13\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  13 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/13 - 71 entities - 6 relations\n",
            "  Page 2/13 - 121 entities\n",
            "  Page 3/13 - 93 entities\n",
            "  Page 4/13 - 106 entities - 4 relations\n",
            "  Page 5/13 - 98 entities\n",
            "  Page 6/13 - 77 entities\n",
            "  Page 7/13 - 81 entities - 7 relations\n",
            "  Page 8/13 - 71 entities\n",
            "  Page 9/13 - 63 entities\n",
            "  Page 10/13 - 112 entities - 12 relations\n",
            "  Page 11/13 - 63 entities\n",
            "  Page 12/13 - 260 entities\n",
            "  Page 13/13 - 155 entities - 5 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 13338 patch vectors (13 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 2044-5040-4-13\n",
            "✓ Completed: 2044-5040-4-13\n",
            "\n",
            "[20/30] - 2103.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 2103\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  16 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/16 - 30 entities - 1 relations\n",
            "  Page 2/16 - 66 entities\n",
            "  Page 3/16 - 34 entities\n",
            "  Page 4/16 - 43 entities - 4 relations\n",
            "  Page 5/16 - 30 entities\n",
            "  Page 6/16 - 24 entities\n",
            "  Page 7/16 - 47 entities - 2 relations\n",
            "  Page 8/16 - 58 entities\n",
            "  Page 9/16 - 74 entities\n",
            "  Page 10/16 - 85 entities - 2 relations\n",
            "  Page 11/16 - 59 entities\n",
            "  Page 12/16 - 39 entities\n",
            "  Page 13/16 - 84 entities - 1 relations\n",
            "  Page 14/16 - 58 entities\n",
            "  Page 15/16 - 106 entities\n",
            "  Page 16/16 - 106 entities - 3 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 16416 patch vectors (16 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 2103\n",
            "✓ Completed: 2103\n",
            "\n",
            "[21/30] - 3065-09.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 3065-09\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  7 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/7 - 39 entities - 3 relations\n",
            "  Page 2/7 - 37 entities\n",
            "  Page 3/7 - 29 entities\n",
            "  Page 4/7 - 24 entities - 0 relations\n",
            "  Page 5/7 - 37 entities\n",
            "  Page 6/7 - 78 entities\n",
            "  Page 7/7 - 145 entities - 0 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 7182 patch vectors (7 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 3065-09\n",
            "✓ Completed: 3065-09\n",
            "\n",
            "[22/30] - 40168_2015_Article_116.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 40168_2015_Article_116\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  18 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/18 - 23 entities - 2 relations\n",
            "  Page 2/18 - 26 entities\n",
            "  Page 3/18 - 12 entities\n",
            "  Page 4/18 - 30 entities - 0 relations\n",
            "  Page 5/18 - 35 entities\n",
            "  Page 6/18 - 22 entities\n",
            "  Page 7/18 - 7 entities - 0 relations\n",
            "  Page 8/18 - 9 entities\n",
            "  Page 9/18 - 12 entities\n",
            "  Page 10/18 - 11 entities - 1 relations\n",
            "  Page 11/18 - 29 entities\n",
            "  Page 12/18 - 28 entities\n",
            "  Page 13/18 - 36 entities - 4 relations\n",
            "  Page 14/18 - 51 entities\n",
            "  Page 15/18 - 42 entities\n",
            "  Page 16/18 - 26 entities - 2 relations\n",
            "  Page 17/18 - 129 entities\n",
            "  Page 18/18 - 78 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 18468 patch vectors (18 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 40168_2015_Article_116\n",
            "✓ Completed: 40168_2015_Article_116\n",
            "\n",
            "[23/30] - 40168_2017_Article_280.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 40168_2017_Article_280\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  16 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/16 - 21 entities - 0 relations\n",
            "  Page 2/16 - 48 entities\n",
            "  Page 3/16 - 34 entities\n",
            "  Page 4/16 - 39 entities - 0 relations\n",
            "  Page 5/16 - 24 entities\n",
            "  Page 6/16 - 31 entities\n",
            "  Page 7/16 - 43 entities - 0 relations\n",
            "  Page 8/16 - 15 entities\n",
            "  Page 9/16 - 16 entities\n",
            "  Page 10/16 - 19 entities - 1 relations\n",
            "  Page 11/16 - 32 entities\n",
            "  Page 12/16 - 11 entities\n",
            "  Page 13/16 - 17 entities - 0 relations\n",
            "  Page 14/16 - 62 entities\n",
            "  Page 15/16 - 128 entities\n",
            "  Page 16/16 - 140 entities - 1 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 16416 patch vectors (16 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 40168_2017_Article_280\n",
            "✓ Completed: 40168_2017_Article_280\n",
            "\n",
            "[24/30] - 40168_2017_Article_330.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 40168_2017_Article_330\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  2 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/2 - 12 entities - 0 relations\n",
            "  Page 2/2 - 16 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 2052 patch vectors (2 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 40168_2017_Article_330\n",
            "✓ Completed: 40168_2017_Article_330\n",
            "\n",
            "[25/30] - 40168_2018_Article_609.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 40168_2018_Article_609\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  1 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/1 - 12 entities - 1 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 1026 patch vectors (1 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 40168_2018_Article_609\n",
            "✓ Completed: 40168_2018_Article_609\n",
            "\n",
            "[26/30] - 40168_2019_Article_666.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 40168_2019_Article_666\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  21 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/21 - 14 entities - 1 relations\n",
            "  Page 2/21 - 47 entities\n",
            "  Page 3/21 - 22 entities\n",
            "  Page 4/21 - 40 entities - 1 relations\n",
            "  Page 5/21 - 18 entities\n",
            "  Page 6/21 - 20 entities\n",
            "  Page 7/21 - 40 entities - 1 relations\n",
            "  Page 8/21 - 23 entities\n",
            "  Page 9/21 - 17 entities\n",
            "  Page 10/21 - 11 entities - 0 relations\n",
            "  Page 11/21 - 31 entities\n",
            "  Page 12/21 - 31 entities\n",
            "  Page 13/21 - 33 entities - 2 relations\n",
            "  Page 14/21 - 47 entities\n",
            "  Page 15/21 - 48 entities\n",
            "  Page 16/21 - 33 entities - 3 relations\n",
            "  Page 17/21 - 25 entities\n",
            "  Page 18/21 - 35 entities\n",
            "  Page 19/21 - 162 entities - 0 relations\n",
            "  Page 20/21 - 159 entities\n",
            "  Page 21/21 - 57 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 21546 patch vectors (21 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 40168_2019_Article_666\n",
            "✓ Completed: 40168_2019_Article_666\n",
            "\n",
            "[27/30] - 40168_2019_Article_724.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 40168_2019_Article_724\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  18 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/18 - 19 entities - 1 relations\n",
            "  Page 2/18 - 24 entities\n",
            "  Page 3/18 - 31 entities\n",
            "  Page 4/18 - 31 entities - 5 relations\n",
            "  Page 5/18 - 34 entities\n",
            "  Page 6/18 - 38 entities\n",
            "  Page 7/18 - 104 entities - 0 relations\n",
            "  Page 8/18 - 40 entities\n",
            "  Page 9/18 - 32 entities\n",
            "  Page 10/18 - 36 entities - 6 relations\n",
            "  Page 11/18 - 38 entities\n",
            "  Page 12/18 - 41 entities\n",
            "  Page 13/18 - 26 entities - 0 relations\n",
            "  Page 14/18 - 25 entities\n",
            "  Page 15/18 - 36 entities\n",
            "  Page 16/18 - 34 entities - 1 relations\n",
            "  Page 17/18 - 152 entities\n",
            "  Page 18/18 - 58 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 18468 patch vectors (18 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 40168_2019_Article_724\n",
            "✓ Completed: 40168_2019_Article_724\n",
            "\n",
            "[28/30] - 40168_2020_Article_830.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 40168_2020_Article_830\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  14 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/14 - 24 entities - 0 relations\n",
            "  Page 2/14 - 47 entities\n",
            "  Page 3/14 - 31 entities\n",
            "  Page 4/14 - 19 entities - 0 relations\n",
            "  Page 5/14 - 32 entities\n",
            "  Page 6/14 - 10 entities\n",
            "  Page 7/14 - 47 entities - 2 relations\n",
            "  Page 8/14 - 46 entities\n",
            "  Page 9/14 - 26 entities\n",
            "  Page 10/14 - 33 entities - 0 relations\n",
            "  Page 11/14 - 43 entities\n",
            "  Page 12/14 - 27 entities\n",
            "  Page 13/14 - 157 entities - 1 relations\n",
            "  Page 14/14 - 126 entities\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 14364 patch vectors (14 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 40168_2020_Article_830\n",
            "✓ Completed: 40168_2020_Article_830\n",
            "\n",
            "[29/30] - 40168_2022_Article_1279.pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 40168_2022_Article_1279\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  16 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/16 - 16 entities - 5 relations\n",
            "  Page 2/16 - 25 entities\n",
            "  Page 3/16 - 6 entities\n",
            "  Page 4/16 - 16 entities - 7 relations\n",
            "  Page 5/16 - 30 entities\n",
            "  Page 6/16 - 46 entities\n",
            "  Page 7/16 - 17 entities - 0 relations\n",
            "  Page 8/16 - 18 entities\n",
            "  Page 9/16 - 38 entities\n",
            "  Page 10/16 - 15 entities - 1 relations\n",
            "  Page 11/16 - 48 entities\n",
            "  Page 12/16 - 16 entities\n",
            "  Page 13/16 - 21 entities - 3 relations\n",
            "  Page 14/16 - 21 entities\n",
            "  Page 15/16 - 76 entities\n",
            "  Page 16/16 - 82 entities - 1 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 16416 patch vectors (16 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 40168_2022_Article_1279\n",
            "✓ Completed: 40168_2022_Article_1279\n",
            "\n",
            "[30/30] - 40168_2022_Article_1293 (1).pdf\n",
            "\n",
            "============================================================\n",
            "Processing: 40168_2022_Article_1293 (1)\n",
            "============================================================\n",
            "→ Converting to images...\n",
            "  19 pages\n",
            "→ Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:2696: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Page 1/19 - 23 entities - 4 relations\n",
            "  Page 2/19 - 22 entities\n",
            "  Page 3/19 - 25 entities\n",
            "  Page 4/19 - 15 entities - 0 relations\n",
            "  Page 5/19 - 10 entities\n",
            "  Page 6/19 - 36 entities\n",
            "  Page 7/19 - 23 entities - 2 relations\n",
            "  Page 8/19 - 38 entities\n",
            "  Page 9/19 - 12 entities\n",
            "  Page 10/19 - 4 entities - 0 relations\n",
            "  Page 11/19 - 19 entities\n",
            "  Page 12/19 - 3 entities\n",
            "  Page 13/19 - 44 entities - 1 relations\n",
            "  Page 14/19 - 51 entities\n",
            "  Page 15/19 - 44 entities\n",
            "  Page 16/19 - 22 entities - 0 relations\n",
            "  Page 17/19 - 40 entities\n",
            "  Page 18/19 - 59 entities\n",
            "  Page 19/19 - 114 entities - 1 relations\n",
            "→ Inserting to Zilliz...\n",
            "  ✓ Inserted 19494 patch vectors (19 pages) to Zilliz\n",
            "  ✓ Cleaned temp files for 40168_2022_Article_1293 (1)\n",
            "✓ Completed: 40168_2022_Article_1293 (1)\n",
            "\n",
            "============================================================\n",
            "PROCESSING SUMMARY\n",
            "============================================================\n",
            "Successful: 30/30\n",
            "\n",
            "============================================================\n",
            "INGESTION COMPLETE\n",
            "============================================================\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 12) Stats and sanity checks\n",
        "def print_stats():\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FINAL STATISTICS\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    # Neo4j stats\n",
        "    try:\n",
        "        with neo4j_driver.session() as session:\n",
        "            stats_queries = {\n",
        "                \"Publications\": \"MATCH (p:Publication) RETURN count(p) as count\",\n",
        "                \"Pages\": \"MATCH (pg:Page) RETURN count(pg) as count\",\n",
        "                \"Entities\": \"MATCH (e:Entity) RETURN count(e) as count\",\n",
        "                \"Unique Entity Types\": \"MATCH (e:Entity) RETURN count(DISTINCT e.entity_type) as count\",\n",
        "                \"Relations\": \"MATCH ()-[r:RELATES]->() RETURN count(r) as count\",\n",
        "                \"Entity Mentions\": \"MATCH ()-[m:MENTIONED_IN]->() RETURN count(m) as count\",\n",
        "            }\n",
        "            print(\"Neo4j Knowledge Graph:\")\n",
        "            for name, query in stats_queries.items():\n",
        "                result = session.run(query)\n",
        "                count = result.single()[\"count\"]\n",
        "                print(f\"  {name:.<35} {count:>10,}\")\n",
        "\n",
        "            print(\"\\nSample Entity Types:\")\n",
        "            result = session.run(\"\"\"\n",
        "                MATCH (e:Entity)\n",
        "                RETURN DISTINCT e.entity_type as type, count(e) as count\n",
        "                ORDER BY count DESC\n",
        "                LIMIT 10\n",
        "            \"\"\")\n",
        "            for record in result:\n",
        "                print(f\"  - {record['type']:.<30} {record['count']:>8,}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Neo4j stats error: {e}\")\n",
        "\n",
        "    # Zilliz stats\n",
        "    try:\n",
        "        zilliz_collection.load()\n",
        "        print(f\"\\nZilliz Vector Store:\")\n",
        "        print(f\"  {'Embeddings':.<35} {zilliz_collection.num_entities:>10,}\")\n",
        "        print(f\"  {'Embedding Dimension':.<35} {EMBEDDING_DIM:>10,}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Zilliz stats error: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "print_stats()\n",
        "\n",
        "if device == \"cuda\":\n",
        "    print(f\"\\nGPU Memory Usage:\")\n",
        "    print(f\"  Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "    print(f\"  Reserved:  {torch.cuda.memory_reserved() / 1e9:.2f} GB\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-04T15:02:16.258Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "kHOwIwBPv8YT",
        "outputId": "4e62a67d-9ff6-4460-e24e-8b6c7eb4a1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FINAL STATISTICS\n",
            "============================================================\n",
            "\n",
            "Neo4j Knowledge Graph:\n",
            "  Publications.......................          0\n",
            "  Pages..............................          0\n",
            "  Entities...........................          0\n",
            "  Unique Entity Types................          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: <GqlStatusObject gql_status='01N51', status_description='warn: relationship type does not exist. The relationship type `RELATES` does not exist in database `neo4j`. Verify that the spelling is correct.', position=<SummaryInputPosition line=1, column=13, offset=12>, raw_classification='UNRECOGNIZED', classification=<NotificationClassification.UNRECOGNIZED: 'UNRECOGNIZED'>, raw_severity='WARNING', severity=<NotificationSeverity.WARNING: 'WARNING'>, diagnostic_record={'_classification': 'UNRECOGNIZED', '_severity': 'WARNING', '_position': {'offset': 12, 'line': 1, 'column': 13}, 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: 'MATCH ()-[r:RELATES]->() RETURN count(r) as count'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Relations..........................          0\n",
            "  Entity Mentions....................          0\n",
            "\n",
            "Sample Entity Types:\n",
            "\n",
            "Zilliz Vector Store:\n",
            "  Embeddings.........................          0\n",
            "  Embedding Dimension................        512\n",
            "\n",
            "============================================================\n",
            "\n",
            "GPU Memory Usage:\n",
            "  Allocated: 0.32 GB\n",
            "  Reserved:  0.34 GB\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 13) Optional: vector search test\n",
        "def test_vector_search(query_text: str = \"protein synthesis\", top_k: int = 5):\n",
        "    print(f\"\\n=== TESTING VECTOR SEARCH ===\")\n",
        "    print(f\"Query: {query_text}\")\n",
        "\n",
        "    from PIL import ImageDraw\n",
        "    img = Image.new('RGB', (400, 100), color='white')\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    draw.text((10, 40), query_text, fill='black')\n",
        "\n",
        "    query_img_path = \"/content/query.png\"\n",
        "    img.save(query_img_path)\n",
        "\n",
        "    # Get multi-vector embedding\n",
        "    query_embeddings = embed_images_colpali([query_img_path])[0]  # shape: [num_patches, dim]\n",
        "\n",
        "    print(f\"Query has {query_embeddings.shape[0]} patch vectors\")\n",
        "\n",
        "    # Search with each patch and aggregate results\n",
        "    all_results = {}\n",
        "    search_params = {\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}}\n",
        "\n",
        "    zilliz_collection.load()\n",
        "\n",
        "    # Search with each query patch\n",
        "    for patch_idx, patch_emb in enumerate(query_embeddings):\n",
        "        results = zilliz_collection.search(\n",
        "            data=[patch_emb.tolist()],\n",
        "            anns_field=\"embedding\",\n",
        "            param=search_params,\n",
        "            limit=top_k * 3,  # Get more to aggregate\n",
        "            output_fields=[\"page_id\", \"pub_id\", \"page_num\", \"patch_num\"]\n",
        "        )\n",
        "\n",
        "        # Aggregate scores by page_id\n",
        "        for hit in results[0]:\n",
        "            page_id = hit.entity.get('page_id')\n",
        "            if page_id not in all_results:\n",
        "                all_results[page_id] = {\n",
        "                    'page_id': page_id,\n",
        "                    'pub_id': hit.entity.get('pub_id'),\n",
        "                    'page_num': hit.entity.get('page_num'),\n",
        "                    'max_score': hit.score,\n",
        "                    'total_score': 0,\n",
        "                    'hits': 0\n",
        "                }\n",
        "            all_results[page_id]['total_score'] += hit.score\n",
        "            all_results[page_id]['hits'] += 1\n",
        "            all_results[page_id]['max_score'] = max(all_results[page_id]['max_score'], hit.score)\n",
        "\n",
        "    # Sort by max score (ColPali's MaxSim approach)\n",
        "    sorted_results = sorted(all_results.values(), key=lambda x: x['max_score'], reverse=True)[:top_k]\n",
        "\n",
        "    print(f\"\\nTop {top_k} Results (aggregated by MaxSim):\")\n",
        "    for i, result in enumerate(sorted_results, 1):\n",
        "        print(f\"{i}. Page: {result['page_id']}, MaxScore: {result['max_score']:.4f}, Hits: {result['hits']}\")\n",
        "\n",
        "    img.close()\n",
        "    return sorted_results\n",
        "\n",
        "# Uncomment to run\n",
        "test_vector_search()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-04T15:02:16.258Z"
        },
        "id": "b6gtck71v8YU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 14) Optional: knowledge graph test\n",
        "def test_knowledge_graph():\n",
        "    print(f\"\\n=== TESTING KNOWLEDGE GRAPH ===\")\n",
        "    with neo4j_driver.session() as session:\n",
        "        result = session.run(\"\"\"\n",
        "            MATCH (e:Entity)-[r]-()\n",
        "            RETURN e.name as entity, e.entity_type as type, count(r) as connections\n",
        "            ORDER BY connections DESC\n",
        "            LIMIT 10\n",
        "        \"\"\")\n",
        "        print(\"\\nMost Connected Entities:\")\n",
        "        for record in result:\n",
        "            print(f\"  {record['entity'][:30]:.<30} ({record['type']}) - {record['connections']} connections\")\n",
        "\n",
        "# Uncomment to run\n",
        "# test_knowledge_graph()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-04T15:02:16.258Z"
        },
        "id": "hcBRbmz6v8YU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 15) Cleanup\n",
        "print(\"\\n=== CLEANUP ===\")\n",
        "try:\n",
        "    neo4j_driver.close()\n",
        "    print(\"✓ Neo4j connection closed\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    connections.disconnect(\"default\")\n",
        "    print(\"✓ Zilliz connection closed\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"✓ GPU cache cleared\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ALL OPERATIONS COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "SUCCESS! Your data is now stored in:\n",
        "- Neo4j: Knowledge graph with entities, relations, and document structure\n",
        "- Zilliz: Vector embeddings for visual similarity search\n",
        "\"\"\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-10-04T15:02:16.258Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpPkYP6Lv8YU",
        "outputId": "7448fa6f-d91f-4824-9e34-786526c17f2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CLEANUP ===\n",
            "✓ Neo4j connection closed\n",
            "✓ Zilliz connection closed\n",
            "✓ GPU cache cleared\n",
            "\n",
            "============================================================\n",
            "ALL OPERATIONS COMPLETE\n",
            "============================================================\n",
            "\n",
            "SUCCESS! Your data is now stored in:\n",
            "- Neo4j: Knowledge graph with entities, relations, and document structure\n",
            "- Zilliz: Vector embeddings for visual similarity search\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    }
  ]
}